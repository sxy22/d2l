{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b1b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c81c7654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d4a9e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4c53c728",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataLoader:  \n",
    "    \"\"\"序列数据的迭代器\"\"\"\n",
    "    def __init__(self, corpus, batch_size, num_steps, vocab_size):\n",
    "        self.corpus = corpus\n",
    "        self.batch_size, self.num_steps = batch_size, num_steps\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.seq_data_iter_sequential(self.corpus, self.batch_size, self.num_steps, self.vocab_size)\n",
    "    \n",
    "    def seq_data_iter_sequential(self, corpus, batch_size, num_steps, vocab_size):\n",
    "        \"\"\"使用顺序分区生成一个小批量子序列\"\"\"\n",
    "        # 从随机偏移量开始划分序列\n",
    "        offset = random.randint(0, num_steps)\n",
    "        num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size\n",
    "        Xs = torch.tensor(corpus[offset: offset + num_tokens], dtype=torch.float32)\n",
    "        Ys = torch.tensor(corpus[offset + 1: offset + 1 + num_tokens], dtype=torch.float32)\n",
    "        Xs, Ys = Xs.reshape(batch_size, -1, vocab_size), Ys.reshape(batch_size, -1, vocab_size)\n",
    "        num_batches = Xs.shape[1] // num_steps\n",
    "        for i in range(0, num_steps * num_batches, num_steps):\n",
    "            X = Xs[:, i: i + num_steps]\n",
    "            Y = Ys[:, i: i + num_steps][:, :, 0]\n",
    "            yield X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e17c91",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6a1d2a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    \"\"\"循环神经网络模型\"\"\"\n",
    "    def __init__(self, rnn_layer, vocab_size, num_item, num_place, item_embed_size=5, place_embed_size=5, **kwargs):\n",
    "        super(RNNModel, self).__init__(**kwargs)\n",
    "        self.rnn = rnn_layer\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_hiddens = self.rnn.hidden_size\n",
    "        if not self.rnn.bidirectional:\n",
    "            self.num_directions = 1\n",
    "            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)\n",
    "        else:\n",
    "            self.num_directions = 2\n",
    "            self.linear = nn.Linear(self.num_hiddens * 2, self.vocab_size)\n",
    "        # item 和 place的embedding\n",
    "        self.num_item = num_item\n",
    "        self.num_place = num_place\n",
    "        self.item_embed_size = item_embed_size\n",
    "        self.place_embed_size = place_embed_size\n",
    "        self.item_embed = nn.Embedding(num_embeddings=num_item, embedding_dim=item_embed_size)\n",
    "        self.place_embed = nn.Embedding(num_embeddings=num_place, embedding_dim=place_embed_size)\n",
    "        \n",
    "\n",
    "    def forward(self, inputs, iid, pid, state):\n",
    "        iid_tensor = torch.full((inputs.shape[0], inputs.shape[1], 1), iid)\n",
    "        pid_tensor = torch.full((inputs.shape[0], inputs.shape[1], 1), pid)\n",
    "        iid_embed = self.item_embed(iid_tensor).view(inputs.shape[0], inputs.shape[1], self.item_embed_size)\n",
    "        pid_embed = self.place_embed(pid_tensor).view(inputs.shape[0], inputs.shape[1], self.place_embed_size)\n",
    "        X = torch.cat((inputs, iid_embed, pid_embed), dim=-1)\n",
    "        # 时间步数*批量大小,隐藏单元数\n",
    "        X.transpose_(0, 1)\n",
    "        X = X.to(torch.float32)\n",
    "        Y, state = self.rnn(X, state)\n",
    "        # 全连接层首先将Y的形状改为(时间步数*批量大小,隐藏单元数)\n",
    "        # 它的输出形状是(时间步数*批量大小,词表大小)。\n",
    "        output = self.linear(Y.reshape((-1, Y.shape[-1])))\n",
    "        return output, state\n",
    "\n",
    "    def begin_state(self, device, batch_size=1):\n",
    "        if not isinstance(self.rnn, nn.LSTM):\n",
    "            # nn.GRU以张量作为隐状态\n",
    "            return  torch.zeros((self.num_directions * self.rnn.num_layers,\n",
    "                                 batch_size, self.num_hiddens),\n",
    "                                device=device)\n",
    "        else:\n",
    "            # nn.LSTM以元组作为隐状态\n",
    "            return (torch.zeros((\n",
    "                self.num_directions * self.rnn.num_layers,\n",
    "                batch_size, self.num_hiddens), device=device),\n",
    "                    torch.zeros((\n",
    "                        self.num_directions * self.rnn.num_layers,\n",
    "                        batch_size, self.num_hiddens), device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c1ef3bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 9 + 3 + 3\n",
    "num_hiddens = 32\n",
    "\n",
    "model = RNNModel(nn.LSTM(num_inputs, num_hiddens), vocab_size=1, num_item=100, num_place=10, item_embed_size=3, place_embed_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c4d6641c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 14, 9])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2055149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, s = model(x, iid=0, pid=0, state=model.begin_state(device='cpu', batch_size=64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "57b7130a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0703e-02],\n",
       "        [ 2.1787e-02],\n",
       "        [-4.0293e-03],\n",
       "        [-5.5603e-02],\n",
       "        [-1.0819e-01],\n",
       "        [-1.5432e-01],\n",
       "        [-1.9241e-01],\n",
       "        [-2.2291e-01],\n",
       "        [-2.4697e-01],\n",
       "        [-2.6586e-01],\n",
       "        [-2.8073e-01],\n",
       "        [-2.9249e-01],\n",
       "        [-3.0187e-01],\n",
       "        [-3.0940e-01],\n",
       "        [-3.1549e-01],\n",
       "        [-3.2046e-01],\n",
       "        [-3.2454e-01],\n",
       "        [-3.2791e-01],\n",
       "        [-3.3071e-01],\n",
       "        [-3.3306e-01],\n",
       "        [-3.3503e-01],\n",
       "        [-3.3670e-01],\n",
       "        [-3.3811e-01],\n",
       "        [-3.3933e-01],\n",
       "        [-3.4038e-01],\n",
       "        [-3.4128e-01],\n",
       "        [-3.4208e-01],\n",
       "        [-3.4277e-01],\n",
       "        [-3.4339e-01],\n",
       "        [-3.4395e-01],\n",
       "        [-3.4445e-01],\n",
       "        [-3.4490e-01],\n",
       "        [-3.4531e-01],\n",
       "        [-3.4570e-01],\n",
       "        [-3.4606e-01],\n",
       "        [-3.4639e-01],\n",
       "        [-3.4671e-01],\n",
       "        [-3.4701e-01],\n",
       "        [-3.4730e-01],\n",
       "        [-3.4758e-01],\n",
       "        [-3.4784e-01],\n",
       "        [-3.4811e-01],\n",
       "        [-3.4836e-01],\n",
       "        [-3.4861e-01],\n",
       "        [-3.4885e-01],\n",
       "        [-3.4909e-01],\n",
       "        [-3.4933e-01],\n",
       "        [-3.4956e-01],\n",
       "        [-3.4979e-01],\n",
       "        [-3.5002e-01],\n",
       "        [-3.5025e-01],\n",
       "        [-3.5047e-01],\n",
       "        [-3.5069e-01],\n",
       "        [-3.5092e-01],\n",
       "        [-3.5114e-01],\n",
       "        [-3.5136e-01],\n",
       "        [-3.5157e-01],\n",
       "        [-3.5179e-01],\n",
       "        [-3.5201e-01],\n",
       "        [-3.5222e-01],\n",
       "        [-3.5244e-01],\n",
       "        [-3.5265e-01],\n",
       "        [-3.5286e-01],\n",
       "        [-3.5307e-01],\n",
       "        [-1.7162e-02],\n",
       "        [ 3.6517e-02],\n",
       "        [-1.2519e-02],\n",
       "        [-9.0898e-02],\n",
       "        [-1.6405e-01],\n",
       "        [-2.2337e-01],\n",
       "        [-2.6862e-01],\n",
       "        [-3.0244e-01],\n",
       "        [-3.2779e-01],\n",
       "        [-3.4705e-01],\n",
       "        [-3.6195e-01],\n",
       "        [-3.7370e-01],\n",
       "        [-3.8313e-01],\n",
       "        [-3.9079e-01],\n",
       "        [-3.9710e-01],\n",
       "        [-4.0233e-01],\n",
       "        [-4.0669e-01],\n",
       "        [-4.1034e-01],\n",
       "        [-4.1341e-01],\n",
       "        [-4.1600e-01],\n",
       "        [-4.1818e-01],\n",
       "        [-4.2003e-01],\n",
       "        [-4.2160e-01],\n",
       "        [-4.2293e-01],\n",
       "        [-4.2406e-01],\n",
       "        [-4.2503e-01],\n",
       "        [-4.2585e-01],\n",
       "        [-4.2656e-01],\n",
       "        [-4.2717e-01],\n",
       "        [-4.2770e-01],\n",
       "        [-4.2816e-01],\n",
       "        [-4.2856e-01],\n",
       "        [-4.2891e-01],\n",
       "        [-4.2922e-01],\n",
       "        [-4.2950e-01],\n",
       "        [-4.2974e-01],\n",
       "        [-4.2996e-01],\n",
       "        [-4.3016e-01],\n",
       "        [-4.3034e-01],\n",
       "        [-4.3051e-01],\n",
       "        [-4.3067e-01],\n",
       "        [-4.3081e-01],\n",
       "        [-4.3095e-01],\n",
       "        [-4.3107e-01],\n",
       "        [-4.3119e-01],\n",
       "        [-4.3131e-01],\n",
       "        [-4.3142e-01],\n",
       "        [-4.3153e-01],\n",
       "        [-4.3164e-01],\n",
       "        [-4.3174e-01],\n",
       "        [-4.3184e-01],\n",
       "        [-4.3193e-01],\n",
       "        [-4.3203e-01],\n",
       "        [-4.3213e-01],\n",
       "        [-4.3222e-01],\n",
       "        [-4.3231e-01],\n",
       "        [-4.3240e-01],\n",
       "        [-4.3249e-01],\n",
       "        [-4.3258e-01],\n",
       "        [-4.3267e-01],\n",
       "        [-4.3276e-01],\n",
       "        [-4.3285e-01],\n",
       "        [-4.3294e-01],\n",
       "        [-4.3303e-01],\n",
       "        [-1.4512e-02],\n",
       "        [ 4.2657e-02],\n",
       "        [-1.7970e-02],\n",
       "        [-1.0695e-01],\n",
       "        [-1.8716e-01],\n",
       "        [-2.4979e-01],\n",
       "        [-2.9562e-01],\n",
       "        [-3.2869e-01],\n",
       "        [-3.5287e-01],\n",
       "        [-3.7101e-01],\n",
       "        [-3.8503e-01],\n",
       "        [-3.9621e-01],\n",
       "        [-4.0536e-01],\n",
       "        [-4.1300e-01],\n",
       "        [-4.1948e-01],\n",
       "        [-4.2500e-01],\n",
       "        [-4.2974e-01],\n",
       "        [-4.3379e-01],\n",
       "        [-4.3726e-01],\n",
       "        [-4.4023e-01],\n",
       "        [-4.4276e-01],\n",
       "        [-4.4491e-01],\n",
       "        [-4.4674e-01],\n",
       "        [-4.4829e-01],\n",
       "        [-4.4960e-01],\n",
       "        [-4.5070e-01],\n",
       "        [-4.5163e-01],\n",
       "        [-4.5240e-01],\n",
       "        [-4.5305e-01],\n",
       "        [-4.5359e-01],\n",
       "        [-4.5404e-01],\n",
       "        [-4.5440e-01],\n",
       "        [-4.5470e-01],\n",
       "        [-4.5495e-01],\n",
       "        [-4.5514e-01],\n",
       "        [-4.5530e-01],\n",
       "        [-4.5542e-01],\n",
       "        [-4.5551e-01],\n",
       "        [-4.5558e-01],\n",
       "        [-4.5562e-01],\n",
       "        [-4.5565e-01],\n",
       "        [-4.5567e-01],\n",
       "        [-4.5567e-01],\n",
       "        [-4.5566e-01],\n",
       "        [-4.5564e-01],\n",
       "        [-4.5561e-01],\n",
       "        [-4.5558e-01],\n",
       "        [-4.5555e-01],\n",
       "        [-4.5551e-01],\n",
       "        [-4.5547e-01],\n",
       "        [-4.5542e-01],\n",
       "        [-4.5537e-01],\n",
       "        [-4.5533e-01],\n",
       "        [-4.5528e-01],\n",
       "        [-4.5523e-01],\n",
       "        [-4.5518e-01],\n",
       "        [-4.5513e-01],\n",
       "        [-4.5508e-01],\n",
       "        [-4.5503e-01],\n",
       "        [-4.5498e-01],\n",
       "        [-4.5493e-01],\n",
       "        [-4.5488e-01],\n",
       "        [-4.5484e-01],\n",
       "        [-4.5479e-01],\n",
       "        [-1.2217e-02],\n",
       "        [ 4.6015e-02],\n",
       "        [-1.9658e-02],\n",
       "        [-1.1243e-01],\n",
       "        [-1.9535e-01],\n",
       "        [-2.5921e-01],\n",
       "        [-3.0501e-01],\n",
       "        [-3.3742e-01],\n",
       "        [-3.6071e-01],\n",
       "        [-3.7793e-01],\n",
       "        [-3.9116e-01],\n",
       "        [-4.0174e-01],\n",
       "        [-4.1055e-01],\n",
       "        [-4.1808e-01],\n",
       "        [-4.2464e-01],\n",
       "        [-4.3040e-01],\n",
       "        [-4.3547e-01],\n",
       "        [-4.3991e-01],\n",
       "        [-4.4379e-01],\n",
       "        [-4.4716e-01],\n",
       "        [-4.5007e-01],\n",
       "        [-4.5257e-01],\n",
       "        [-4.5471e-01],\n",
       "        [-4.5653e-01],\n",
       "        [-4.5807e-01],\n",
       "        [-4.5936e-01],\n",
       "        [-4.6044e-01],\n",
       "        [-4.6133e-01],\n",
       "        [-4.6207e-01],\n",
       "        [-4.6267e-01],\n",
       "        [-4.6316e-01],\n",
       "        [-4.6354e-01],\n",
       "        [-4.6384e-01],\n",
       "        [-4.6407e-01],\n",
       "        [-4.6424e-01],\n",
       "        [-4.6435e-01],\n",
       "        [-4.6442e-01],\n",
       "        [-4.6445e-01],\n",
       "        [-4.6445e-01],\n",
       "        [-4.6442e-01],\n",
       "        [-4.6437e-01],\n",
       "        [-4.6430e-01],\n",
       "        [-4.6422e-01],\n",
       "        [-4.6412e-01],\n",
       "        [-4.6402e-01],\n",
       "        [-4.6390e-01],\n",
       "        [-4.6378e-01],\n",
       "        [-4.6365e-01],\n",
       "        [-4.6351e-01],\n",
       "        [-4.6338e-01],\n",
       "        [-4.6324e-01],\n",
       "        [-4.6310e-01],\n",
       "        [-4.6295e-01],\n",
       "        [-4.6281e-01],\n",
       "        [-4.6267e-01],\n",
       "        [-4.6253e-01],\n",
       "        [-4.6239e-01],\n",
       "        [-4.6225e-01],\n",
       "        [-4.6211e-01],\n",
       "        [-4.6197e-01],\n",
       "        [-4.6184e-01],\n",
       "        [-4.6170e-01],\n",
       "        [-4.6157e-01],\n",
       "        [-4.6144e-01],\n",
       "        [-1.0215e-02],\n",
       "        [ 4.8104e-02],\n",
       "        [-1.9330e-02],\n",
       "        [-1.1296e-01],\n",
       "        [-1.9702e-01],\n",
       "        [-2.6172e-01],\n",
       "        [-3.0769e-01],\n",
       "        [-3.3980e-01],\n",
       "        [-3.6253e-01],\n",
       "        [-3.7907e-01],\n",
       "        [-3.9159e-01],\n",
       "        [-4.0156e-01],\n",
       "        [-4.0992e-01],\n",
       "        [-4.1720e-01],\n",
       "        [-4.2370e-01],\n",
       "        [-4.2956e-01],\n",
       "        [-4.3485e-01],\n",
       "        [-4.3961e-01],\n",
       "        [-4.4385e-01],\n",
       "        [-4.4760e-01],\n",
       "        [-4.5089e-01],\n",
       "        [-4.5376e-01],\n",
       "        [-4.5623e-01],\n",
       "        [-4.5835e-01],\n",
       "        [-4.6015e-01],\n",
       "        [-4.6168e-01],\n",
       "        [-4.6296e-01],\n",
       "        [-4.6402e-01],\n",
       "        [-4.6490e-01],\n",
       "        [-4.6562e-01],\n",
       "        [-4.6620e-01],\n",
       "        [-4.6665e-01],\n",
       "        [-4.6701e-01],\n",
       "        [-4.6727e-01],\n",
       "        [-4.6746e-01],\n",
       "        [-4.6759e-01],\n",
       "        [-4.6766e-01],\n",
       "        [-4.6769e-01],\n",
       "        [-4.6767e-01],\n",
       "        [-4.6762e-01],\n",
       "        [-4.6755e-01],\n",
       "        [-4.6745e-01],\n",
       "        [-4.6733e-01],\n",
       "        [-4.6720e-01],\n",
       "        [-4.6705e-01],\n",
       "        [-4.6690e-01],\n",
       "        [-4.6673e-01],\n",
       "        [-4.6656e-01],\n",
       "        [-4.6638e-01],\n",
       "        [-4.6620e-01],\n",
       "        [-4.6601e-01],\n",
       "        [-4.6582e-01],\n",
       "        [-4.6563e-01],\n",
       "        [-4.6545e-01],\n",
       "        [-4.6526e-01],\n",
       "        [-4.6507e-01],\n",
       "        [-4.6488e-01],\n",
       "        [-4.6470e-01],\n",
       "        [-4.6451e-01],\n",
       "        [-4.6433e-01],\n",
       "        [-4.6415e-01],\n",
       "        [-4.6398e-01],\n",
       "        [-4.6380e-01],\n",
       "        [-4.6363e-01],\n",
       "        [-8.4755e-03],\n",
       "        [ 4.9468e-02],\n",
       "        [-1.8159e-02],\n",
       "        [-1.1136e-01],\n",
       "        [-1.9595e-01],\n",
       "        [-2.6144e-01],\n",
       "        [-3.0777e-01],\n",
       "        [-3.3983e-01],\n",
       "        [-3.6223e-01],\n",
       "        [-3.7824e-01],\n",
       "        [-3.9015e-01],\n",
       "        [-3.9952e-01],\n",
       "        [-4.0736e-01],\n",
       "        [-4.1427e-01],\n",
       "        [-4.2057e-01],\n",
       "        [-4.2641e-01],\n",
       "        [-4.3181e-01],\n",
       "        [-4.3679e-01],\n",
       "        [-4.4132e-01],\n",
       "        [-4.4541e-01],\n",
       "        [-4.4905e-01],\n",
       "        [-4.5227e-01],\n",
       "        [-4.5508e-01],\n",
       "        [-4.5751e-01],\n",
       "        [-4.5961e-01],\n",
       "        [-4.6139e-01],\n",
       "        [-4.6290e-01],\n",
       "        [-4.6417e-01],\n",
       "        [-4.6522e-01],\n",
       "        [-4.6609e-01],\n",
       "        [-4.6680e-01],\n",
       "        [-4.6736e-01],\n",
       "        [-4.6781e-01],\n",
       "        [-4.6815e-01],\n",
       "        [-4.6840e-01],\n",
       "        [-4.6857e-01],\n",
       "        [-4.6868e-01],\n",
       "        [-4.6874e-01],\n",
       "        [-4.6874e-01],\n",
       "        [-4.6871e-01],\n",
       "        [-4.6864e-01],\n",
       "        [-4.6855e-01],\n",
       "        [-4.6843e-01],\n",
       "        [-4.6829e-01],\n",
       "        [-4.6814e-01],\n",
       "        [-4.6797e-01],\n",
       "        [-4.6779e-01],\n",
       "        [-4.6761e-01],\n",
       "        [-4.6741e-01],\n",
       "        [-4.6721e-01],\n",
       "        [-4.6701e-01],\n",
       "        [-4.6681e-01],\n",
       "        [-4.6660e-01],\n",
       "        [-4.6639e-01],\n",
       "        [-4.6618e-01],\n",
       "        [-4.6598e-01],\n",
       "        [-4.6577e-01],\n",
       "        [-4.6557e-01],\n",
       "        [-4.6536e-01],\n",
       "        [-4.6516e-01],\n",
       "        [-4.6496e-01],\n",
       "        [-4.6477e-01],\n",
       "        [-4.6458e-01],\n",
       "        [-4.6439e-01],\n",
       "        [-6.9544e-03],\n",
       "        [ 5.0364e-02],\n",
       "        [-1.6755e-02],\n",
       "        [-1.0900e-01],\n",
       "        [-1.9384e-01],\n",
       "        [-2.6011e-01],\n",
       "        [-3.0693e-01],\n",
       "        [-3.3909e-01],\n",
       "        [-3.6128e-01],\n",
       "        [-3.7689e-01],\n",
       "        [-3.8828e-01],\n",
       "        [-3.9709e-01],\n",
       "        [-4.0440e-01],\n",
       "        [-4.1088e-01],\n",
       "        [-4.1689e-01],\n",
       "        [-4.2258e-01],\n",
       "        [-4.2799e-01],\n",
       "        [-4.3309e-01],\n",
       "        [-4.3784e-01],\n",
       "        [-4.4220e-01],\n",
       "        [-4.4616e-01],\n",
       "        [-4.4970e-01],\n",
       "        [-4.5283e-01],\n",
       "        [-4.5558e-01],\n",
       "        [-4.5796e-01],\n",
       "        [-4.6001e-01],\n",
       "        [-4.6176e-01],\n",
       "        [-4.6325e-01],\n",
       "        [-4.6449e-01],\n",
       "        [-4.6553e-01],\n",
       "        [-4.6638e-01],\n",
       "        [-4.6708e-01],\n",
       "        [-4.6763e-01],\n",
       "        [-4.6807e-01],\n",
       "        [-4.6840e-01],\n",
       "        [-4.6864e-01],\n",
       "        [-4.6881e-01],\n",
       "        [-4.6891e-01],\n",
       "        [-4.6896e-01],\n",
       "        [-4.6896e-01],\n",
       "        [-4.6892e-01],\n",
       "        [-4.6885e-01],\n",
       "        [-4.6875e-01],\n",
       "        [-4.6862e-01],\n",
       "        [-4.6848e-01],\n",
       "        [-4.6832e-01],\n",
       "        [-4.6814e-01],\n",
       "        [-4.6796e-01],\n",
       "        [-4.6777e-01],\n",
       "        [-4.6757e-01],\n",
       "        [-4.6736e-01],\n",
       "        [-4.6715e-01],\n",
       "        [-4.6694e-01],\n",
       "        [-4.6673e-01],\n",
       "        [-4.6651e-01],\n",
       "        [-4.6630e-01],\n",
       "        [-4.6609e-01],\n",
       "        [-4.6587e-01],\n",
       "        [-4.6566e-01],\n",
       "        [-4.6546e-01],\n",
       "        [-4.6525e-01],\n",
       "        [-4.6505e-01],\n",
       "        [-4.6485e-01],\n",
       "        [-4.6465e-01],\n",
       "        [-5.6020e-03],\n",
       "        [ 5.0941e-02],\n",
       "        [-1.5398e-02],\n",
       "        [-1.0649e-01],\n",
       "        [-1.9141e-01],\n",
       "        [-2.5846e-01],\n",
       "        [-3.0585e-01],\n",
       "        [-3.3819e-01],\n",
       "        [-3.6028e-01],\n",
       "        [-3.7559e-01],\n",
       "        [-3.8655e-01],\n",
       "        [-3.9485e-01],\n",
       "        [-4.0165e-01],\n",
       "        [-4.0767e-01],\n",
       "        [-4.1332e-01],\n",
       "        [-4.1878e-01],\n",
       "        [-4.2410e-01],\n",
       "        [-4.2923e-01],\n",
       "        [-4.3412e-01],\n",
       "        [-4.3869e-01],\n",
       "        [-4.4291e-01],\n",
       "        [-4.4673e-01],\n",
       "        [-4.5016e-01],\n",
       "        [-4.5320e-01],\n",
       "        [-4.5587e-01],\n",
       "        [-4.5818e-01],\n",
       "        [-4.6018e-01],\n",
       "        [-4.6188e-01],\n",
       "        [-4.6332e-01],\n",
       "        [-4.6454e-01],\n",
       "        [-4.6555e-01],\n",
       "        [-4.6638e-01],\n",
       "        [-4.6705e-01],\n",
       "        [-4.6759e-01],\n",
       "        [-4.6802e-01],\n",
       "        [-4.6834e-01],\n",
       "        [-4.6857e-01],\n",
       "        [-4.6873e-01],\n",
       "        [-4.6883e-01],\n",
       "        [-4.6887e-01],\n",
       "        [-4.6887e-01],\n",
       "        [-4.6883e-01],\n",
       "        [-4.6875e-01],\n",
       "        [-4.6865e-01],\n",
       "        [-4.6852e-01],\n",
       "        [-4.6838e-01],\n",
       "        [-4.6821e-01],\n",
       "        [-4.6804e-01],\n",
       "        [-4.6785e-01],\n",
       "        [-4.6766e-01],\n",
       "        [-4.6746e-01],\n",
       "        [-4.6725e-01],\n",
       "        [-4.6704e-01],\n",
       "        [-4.6683e-01],\n",
       "        [-4.6662e-01],\n",
       "        [-4.6640e-01],\n",
       "        [-4.6619e-01],\n",
       "        [-4.6598e-01],\n",
       "        [-4.6577e-01],\n",
       "        [-4.6556e-01],\n",
       "        [-4.6535e-01],\n",
       "        [-4.6514e-01],\n",
       "        [-4.6494e-01],\n",
       "        [-4.6474e-01],\n",
       "        [-4.3729e-03],\n",
       "        [ 5.1292e-02],\n",
       "        [-1.4198e-02],\n",
       "        [-1.0410e-01],\n",
       "        [-1.8900e-01],\n",
       "        [-2.5679e-01],\n",
       "        [-3.0479e-01],\n",
       "        [-3.3738e-01],\n",
       "        [-3.5942e-01],\n",
       "        [-3.7450e-01],\n",
       "        [-3.8510e-01],\n",
       "        [-3.9296e-01],\n",
       "        [-3.9929e-01],\n",
       "        [-4.0484e-01],\n",
       "        [-4.1010e-01],\n",
       "        [-4.1527e-01],\n",
       "        [-4.2042e-01],\n",
       "        [-4.2551e-01],\n",
       "        [-4.3046e-01],\n",
       "        [-4.3519e-01],\n",
       "        [-4.3961e-01],\n",
       "        [-4.4368e-01],\n",
       "        [-4.4737e-01],\n",
       "        [-4.5068e-01],\n",
       "        [-4.5361e-01],\n",
       "        [-4.5618e-01],\n",
       "        [-4.5841e-01],\n",
       "        [-4.6033e-01],\n",
       "        [-4.6197e-01],\n",
       "        [-4.6336e-01],\n",
       "        [-4.6453e-01],\n",
       "        [-4.6550e-01],\n",
       "        [-4.6630e-01],\n",
       "        [-4.6695e-01],\n",
       "        [-4.6747e-01],\n",
       "        [-4.6787e-01],\n",
       "        [-4.6818e-01],\n",
       "        [-4.6840e-01],\n",
       "        [-4.6855e-01],\n",
       "        [-4.6864e-01],\n",
       "        [-4.6868e-01],\n",
       "        [-4.6867e-01],\n",
       "        [-4.6863e-01],\n",
       "        [-4.6855e-01],\n",
       "        [-4.6844e-01],\n",
       "        [-4.6832e-01],\n",
       "        [-4.6817e-01],\n",
       "        [-4.6801e-01],\n",
       "        [-4.6783e-01],\n",
       "        [-4.6765e-01],\n",
       "        [-4.6746e-01],\n",
       "        [-4.6726e-01],\n",
       "        [-4.6705e-01],\n",
       "        [-4.6685e-01],\n",
       "        [-4.6664e-01],\n",
       "        [-4.6643e-01],\n",
       "        [-4.6622e-01],\n",
       "        [-4.6600e-01],\n",
       "        [-4.6579e-01],\n",
       "        [-4.6559e-01],\n",
       "        [-4.6538e-01],\n",
       "        [-4.6517e-01],\n",
       "        [-4.6497e-01],\n",
       "        [-4.6477e-01],\n",
       "        [-3.2310e-03],\n",
       "        [ 5.1482e-02],\n",
       "        [-1.3189e-02],\n",
       "        [-1.0191e-01],\n",
       "        [-1.8672e-01],\n",
       "        [-2.5519e-01],\n",
       "        [-3.0382e-01],\n",
       "        [-3.3670e-01],\n",
       "        [-3.5876e-01],\n",
       "        [-3.7366e-01],\n",
       "        [-3.8397e-01],\n",
       "        [-3.9145e-01],\n",
       "        [-3.9734e-01],\n",
       "        [-4.0246e-01],\n",
       "        [-4.0731e-01],\n",
       "        [-4.1215e-01],\n",
       "        [-4.1708e-01],\n",
       "        [-4.2206e-01],\n",
       "        [-4.2701e-01],\n",
       "        [-4.3182e-01],\n",
       "        [-4.3640e-01],\n",
       "        [-4.4067e-01],\n",
       "        [-4.4460e-01],\n",
       "        [-4.4815e-01],\n",
       "        [-4.5133e-01],\n",
       "        [-4.5413e-01],\n",
       "        [-4.5659e-01],\n",
       "        [-4.5872e-01],\n",
       "        [-4.6055e-01],\n",
       "        [-4.6212e-01],\n",
       "        [-4.6344e-01],\n",
       "        [-4.6455e-01],\n",
       "        [-4.6548e-01],\n",
       "        [-4.6624e-01],\n",
       "        [-4.6685e-01],\n",
       "        [-4.6734e-01],\n",
       "        [-4.6772e-01],\n",
       "        [-4.6801e-01],\n",
       "        [-4.6822e-01],\n",
       "        [-4.6835e-01],\n",
       "        [-4.6843e-01],\n",
       "        [-4.6846e-01],\n",
       "        [-4.6845e-01],\n",
       "        [-4.6840e-01],\n",
       "        [-4.6832e-01],\n",
       "        [-4.6821e-01],\n",
       "        [-4.6808e-01],\n",
       "        [-4.6793e-01],\n",
       "        [-4.6777e-01],\n",
       "        [-4.6760e-01],\n",
       "        [-4.6742e-01],\n",
       "        [-4.6723e-01],\n",
       "        [-4.6703e-01],\n",
       "        [-4.6683e-01],\n",
       "        [-4.6662e-01],\n",
       "        [-4.6642e-01],\n",
       "        [-4.6621e-01],\n",
       "        [-4.6600e-01],\n",
       "        [-4.6579e-01],\n",
       "        [-4.6559e-01],\n",
       "        [-4.6538e-01],\n",
       "        [-4.6518e-01],\n",
       "        [-4.6497e-01],\n",
       "        [-4.6478e-01],\n",
       "        [-2.1497e-03],\n",
       "        [ 5.1555e-02],\n",
       "        [-1.2367e-02],\n",
       "        [-9.9964e-02],\n",
       "        [-1.8460e-01],\n",
       "        [-2.5369e-01],\n",
       "        [-3.0295e-01],\n",
       "        [-3.3616e-01],\n",
       "        [-3.5827e-01],\n",
       "        [-3.7305e-01],\n",
       "        [-3.8311e-01],\n",
       "        [-3.9027e-01],\n",
       "        [-3.9578e-01],\n",
       "        [-4.0048e-01],\n",
       "        [-4.0493e-01],\n",
       "        [-4.0943e-01],\n",
       "        [-4.1409e-01],\n",
       "        [-4.1892e-01],\n",
       "        [-4.2380e-01],\n",
       "        [-4.2865e-01],\n",
       "        [-4.3334e-01],\n",
       "        [-4.3777e-01],\n",
       "        [-4.4190e-01],\n",
       "        [-4.4566e-01],\n",
       "        [-4.4906e-01],\n",
       "        [-4.5209e-01],\n",
       "        [-4.5476e-01],\n",
       "        [-4.5709e-01],\n",
       "        [-4.5911e-01],\n",
       "        [-4.6085e-01],\n",
       "        [-4.6233e-01],\n",
       "        [-4.6358e-01],\n",
       "        [-4.6462e-01],\n",
       "        [-4.6549e-01],\n",
       "        [-4.6620e-01],\n",
       "        [-4.6677e-01],\n",
       "        [-4.6723e-01],\n",
       "        [-4.6758e-01],\n",
       "        [-4.6785e-01],\n",
       "        [-4.6804e-01],\n",
       "        [-4.6816e-01],\n",
       "        [-4.6822e-01],\n",
       "        [-4.6824e-01],\n",
       "        [-4.6822e-01],\n",
       "        [-4.6816e-01],\n",
       "        [-4.6808e-01],\n",
       "        [-4.6797e-01],\n",
       "        [-4.6784e-01],\n",
       "        [-4.6769e-01],\n",
       "        [-4.6753e-01],\n",
       "        [-4.6736e-01],\n",
       "        [-4.6718e-01],\n",
       "        [-4.6699e-01],\n",
       "        [-4.6679e-01],\n",
       "        [-4.6659e-01],\n",
       "        [-4.6639e-01],\n",
       "        [-4.6619e-01],\n",
       "        [-4.6598e-01],\n",
       "        [-4.6578e-01],\n",
       "        [-4.6557e-01],\n",
       "        [-4.6537e-01],\n",
       "        [-4.6517e-01],\n",
       "        [-4.6497e-01],\n",
       "        [-4.6477e-01],\n",
       "        [-1.1109e-03],\n",
       "        [ 5.1544e-02],\n",
       "        [-1.1717e-02],\n",
       "        [-9.8239e-02],\n",
       "        [-1.8264e-01],\n",
       "        [-2.5228e-01],\n",
       "        [-3.0217e-01],\n",
       "        [-3.3574e-01],\n",
       "        [-3.5794e-01],\n",
       "        [-3.7262e-01],\n",
       "        [-3.8249e-01],\n",
       "        [-3.8937e-01],\n",
       "        [-3.9454e-01],\n",
       "        [-3.9886e-01],\n",
       "        [-4.0293e-01],\n",
       "        [-4.0707e-01],\n",
       "        [-4.1145e-01],\n",
       "        [-4.1607e-01],\n",
       "        [-4.2086e-01],\n",
       "        [-4.2569e-01],\n",
       "        [-4.3044e-01],\n",
       "        [-4.3500e-01],\n",
       "        [-4.3929e-01],\n",
       "        [-4.4325e-01],\n",
       "        [-4.4685e-01],\n",
       "        [-4.5008e-01],\n",
       "        [-4.5295e-01],\n",
       "        [-4.5548e-01],\n",
       "        [-4.5768e-01],\n",
       "        [-4.5958e-01],\n",
       "        [-4.6120e-01],\n",
       "        [-4.6259e-01],\n",
       "        [-4.6376e-01],\n",
       "        [-4.6473e-01],\n",
       "        [-4.6554e-01],\n",
       "        [-4.6620e-01],\n",
       "        [-4.6673e-01],\n",
       "        [-4.6715e-01],\n",
       "        [-4.6747e-01],\n",
       "        [-4.6771e-01],\n",
       "        [-4.6787e-01],\n",
       "        [-4.6798e-01],\n",
       "        [-4.6803e-01],\n",
       "        [-4.6803e-01],\n",
       "        [-4.6800e-01],\n",
       "        [-4.6794e-01],\n",
       "        [-4.6785e-01],\n",
       "        [-4.6773e-01],\n",
       "        [-4.6760e-01],\n",
       "        [-4.6745e-01],\n",
       "        [-4.6729e-01],\n",
       "        [-4.6712e-01],\n",
       "        [-4.6694e-01],\n",
       "        [-4.6675e-01],\n",
       "        [-4.6656e-01],\n",
       "        [-4.6636e-01],\n",
       "        [-4.6616e-01],\n",
       "        [-4.6596e-01],\n",
       "        [-4.6576e-01],\n",
       "        [-4.6556e-01],\n",
       "        [-4.6536e-01],\n",
       "        [-4.6516e-01],\n",
       "        [-4.6496e-01],\n",
       "        [-4.6476e-01],\n",
       "        [-1.0226e-04],\n",
       "        [ 5.1473e-02],\n",
       "        [-1.1221e-02],\n",
       "        [-9.6718e-02],\n",
       "        [-1.8083e-01],\n",
       "        [-2.5093e-01],\n",
       "        [-3.0144e-01],\n",
       "        [-3.3541e-01],\n",
       "        [-3.5772e-01],\n",
       "        [-3.7235e-01],\n",
       "        [-3.8205e-01],\n",
       "        [-3.8869e-01],\n",
       "        [-3.9357e-01],\n",
       "        [-3.9755e-01],\n",
       "        [-4.0125e-01],\n",
       "        [-4.0505e-01],\n",
       "        [-4.0912e-01],\n",
       "        [-4.1351e-01],\n",
       "        [-4.1816e-01],\n",
       "        [-4.2294e-01],\n",
       "        [-4.2772e-01],\n",
       "        [-4.3237e-01],\n",
       "        [-4.3679e-01],\n",
       "        [-4.4091e-01],\n",
       "        [-4.4469e-01],\n",
       "        [-4.4812e-01],\n",
       "        [-4.5118e-01],\n",
       "        [-4.5388e-01],\n",
       "        [-4.5625e-01],\n",
       "        [-4.5831e-01],\n",
       "        [-4.6009e-01],\n",
       "        [-4.6160e-01],\n",
       "        [-4.6289e-01],\n",
       "        [-4.6397e-01],\n",
       "        [-4.6487e-01],\n",
       "        [-4.6562e-01],\n",
       "        [-4.6622e-01],\n",
       "        [-4.6670e-01],\n",
       "        [-4.6708e-01],\n",
       "        [-4.6737e-01],\n",
       "        [-4.6758e-01],\n",
       "        [-4.6772e-01],\n",
       "        [-4.6781e-01],\n",
       "        [-4.6784e-01],\n",
       "        [-4.6784e-01],\n",
       "        [-4.6779e-01],\n",
       "        [-4.6772e-01],\n",
       "        [-4.6762e-01],\n",
       "        [-4.6751e-01],\n",
       "        [-4.6737e-01],\n",
       "        [-4.6722e-01],\n",
       "        [-4.6706e-01],\n",
       "        [-4.6688e-01],\n",
       "        [-4.6670e-01],\n",
       "        [-4.6652e-01],\n",
       "        [-4.6632e-01],\n",
       "        [-4.6613e-01],\n",
       "        [-4.6593e-01],\n",
       "        [-4.6573e-01],\n",
       "        [-4.6554e-01],\n",
       "        [-4.6534e-01],\n",
       "        [-4.6514e-01],\n",
       "        [-4.6494e-01],\n",
       "        [-4.6475e-01],\n",
       "        [ 8.8401e-04],\n",
       "        [ 5.1357e-02],\n",
       "        [-1.0858e-02],\n",
       "        [-9.5381e-02],\n",
       "        [-1.7917e-01],\n",
       "        [-2.4965e-01],\n",
       "        [-3.0076e-01],\n",
       "        [-3.3514e-01],\n",
       "        [-3.5760e-01],\n",
       "        [-3.7219e-01],\n",
       "        [-3.8175e-01],\n",
       "        [-3.8819e-01],\n",
       "        [-3.9281e-01],\n",
       "        [-3.9649e-01],\n",
       "        [-3.9986e-01],\n",
       "        [-4.0331e-01],\n",
       "        [-4.0708e-01],\n",
       "        [-4.1122e-01],\n",
       "        [-4.1570e-01],\n",
       "        [-4.2039e-01],\n",
       "        [-4.2516e-01],\n",
       "        [-4.2987e-01],\n",
       "        [-4.3440e-01],\n",
       "        [-4.3866e-01],\n",
       "        [-4.4261e-01],\n",
       "        [-4.4620e-01],\n",
       "        [-4.4943e-01],\n",
       "        [-4.5231e-01],\n",
       "        [-4.5485e-01],\n",
       "        [-4.5706e-01],\n",
       "        [-4.5898e-01],\n",
       "        [-4.6062e-01],\n",
       "        [-4.6203e-01],\n",
       "        [-4.6321e-01],\n",
       "        [-4.6421e-01],\n",
       "        [-4.6503e-01],\n",
       "        [-4.6571e-01],\n",
       "        [-4.6626e-01],\n",
       "        [-4.6669e-01],\n",
       "        [-4.6703e-01],\n",
       "        [-4.6728e-01],\n",
       "        [-4.6746e-01],\n",
       "        [-4.6758e-01],\n",
       "        [-4.6765e-01],\n",
       "        [-4.6767e-01],\n",
       "        [-4.6765e-01],\n",
       "        [-4.6759e-01],\n",
       "        [-4.6751e-01],\n",
       "        [-4.6741e-01],\n",
       "        [-4.6728e-01],\n",
       "        [-4.6714e-01],\n",
       "        [-4.6699e-01],\n",
       "        [-4.6683e-01],\n",
       "        [-4.6665e-01],\n",
       "        [-4.6647e-01],\n",
       "        [-4.6629e-01],\n",
       "        [-4.6610e-01],\n",
       "        [-4.6590e-01],\n",
       "        [-4.6571e-01],\n",
       "        [-4.6551e-01],\n",
       "        [-4.6532e-01],\n",
       "        [-4.6512e-01],\n",
       "        [-4.6493e-01],\n",
       "        [-4.6474e-01]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701a8ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_steps = 32, 35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d735ef0b",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf5f58df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rnn(inputs, iid, pid, num_preds, net, device):\n",
    "    \"\"\"向后预测\"\"\"\n",
    "    state = net.begin_state(batch_size=1, device=device)\n",
    "    outputs = inputs.flatten().tolist() \n",
    "    # 预热\n",
    "    Y, state = net(inputs, iid=iid, pid=pid, state=state)\n",
    "    # 向后第一步\n",
    "    outputs.append(Y.flatten()[-1].item())\n",
    "    for _ in range(num_preds - 1):  # 预测num_preds步\n",
    "        Y, state = net(torch.tensor(outputs[-1]).view(1, 1, 1), iid=iid, pid=pid, state=state)\n",
    "        outputs.append(Y.item())\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5de9634",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "913d953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping(net, theta):  #@save\n",
    "    \"\"\"裁剪梯度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d2914844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(net, train_iter, iid, pid, loss, updater, device, use_random_iter):\n",
    "    \"\"\"训练网络一个迭代周期\"\"\"\n",
    "    state = None\n",
    "    start_time = time.time()\n",
    "    mse = 0\n",
    "    size = 0\n",
    "    for X, Y in train_iter:\n",
    "        if state is None or use_random_iter:\n",
    "            # 在第一次迭代或使用随机抽样时初始化state\n",
    "            state = net.begin_state(batch_size=X.shape[0], device=device)\n",
    "        else:\n",
    "            if isinstance(net, nn.Module) and not isinstance(state, tuple):\n",
    "                # state对于nn.GRU是个张量\n",
    "                state.detach_()\n",
    "            else:\n",
    "                for s in state:\n",
    "                    s.detach_()\n",
    "                    \n",
    "        y = Y.reshape(-1)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat, state = net(X, iid, pid, state)\n",
    "        l = loss(y_hat.reshape(-1), y)\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            updater.zero_grad()\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            updater.step()\n",
    "        else:\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            # 因为已经调用了mean函数\n",
    "            updater(batch_size=1)\n",
    "        mse += l * y.numel()\n",
    "        size += y.numel()\n",
    "    \n",
    "    return mse / size, time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9ec595a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, iid, pid, lr, num_epochs, device, use_random_iter=False):\n",
    "    \"\"\"训练模型\"\"\"\n",
    "    loss = nn.MSELoss()\n",
    "    # 初始化\n",
    "    updater = torch.optim.Adam(net.parameters(), lr)\n",
    "    # 训练\n",
    "    for epoch in range(num_epochs):\n",
    "        epochmse, speed = train_epoch(\n",
    "            net, train_iter, iid, pid, loss, updater, device, use_random_iter)\n",
    "        if (epoch) % 50 == 0:\n",
    "            print(f'epoch: {epoch + 1}, mse: {epochmse}, time: {speed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3a8ac018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sale</th>\n",
       "      <th>pre_1</th>\n",
       "      <th>pre_2</th>\n",
       "      <th>pre_3</th>\n",
       "      <th>pre_4</th>\n",
       "      <th>pre_5</th>\n",
       "      <th>pre_6</th>\n",
       "      <th>pre_7</th>\n",
       "      <th>pre_8</th>\n",
       "      <th>pre_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pre_21</th>\n",
       "      <th>pre_22</th>\n",
       "      <th>pre_23</th>\n",
       "      <th>pre_24</th>\n",
       "      <th>pre_25</th>\n",
       "      <th>pre_26</th>\n",
       "      <th>pre_27</th>\n",
       "      <th>pre_28</th>\n",
       "      <th>pre_29</th>\n",
       "      <th>pre_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>9994.0</td>\n",
       "      <td>9993.0</td>\n",
       "      <td>9992.0</td>\n",
       "      <td>9991.0</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>9989.0</td>\n",
       "      <td>9988.0</td>\n",
       "      <td>9987.0</td>\n",
       "      <td>9986.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9974.0</td>\n",
       "      <td>9973.0</td>\n",
       "      <td>9972.0</td>\n",
       "      <td>9971.0</td>\n",
       "      <td>9970.0</td>\n",
       "      <td>9969.0</td>\n",
       "      <td>9968.0</td>\n",
       "      <td>9967.0</td>\n",
       "      <td>9966.0</td>\n",
       "      <td>9965.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>9995.0</td>\n",
       "      <td>9994.0</td>\n",
       "      <td>9993.0</td>\n",
       "      <td>9992.0</td>\n",
       "      <td>9991.0</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>9989.0</td>\n",
       "      <td>9988.0</td>\n",
       "      <td>9987.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9975.0</td>\n",
       "      <td>9974.0</td>\n",
       "      <td>9973.0</td>\n",
       "      <td>9972.0</td>\n",
       "      <td>9971.0</td>\n",
       "      <td>9970.0</td>\n",
       "      <td>9969.0</td>\n",
       "      <td>9968.0</td>\n",
       "      <td>9967.0</td>\n",
       "      <td>9966.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>9996.0</td>\n",
       "      <td>9995.0</td>\n",
       "      <td>9994.0</td>\n",
       "      <td>9993.0</td>\n",
       "      <td>9992.0</td>\n",
       "      <td>9991.0</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>9989.0</td>\n",
       "      <td>9988.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9976.0</td>\n",
       "      <td>9975.0</td>\n",
       "      <td>9974.0</td>\n",
       "      <td>9973.0</td>\n",
       "      <td>9972.0</td>\n",
       "      <td>9971.0</td>\n",
       "      <td>9970.0</td>\n",
       "      <td>9969.0</td>\n",
       "      <td>9968.0</td>\n",
       "      <td>9967.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>9997.0</td>\n",
       "      <td>9996.0</td>\n",
       "      <td>9995.0</td>\n",
       "      <td>9994.0</td>\n",
       "      <td>9993.0</td>\n",
       "      <td>9992.0</td>\n",
       "      <td>9991.0</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>9989.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9977.0</td>\n",
       "      <td>9976.0</td>\n",
       "      <td>9975.0</td>\n",
       "      <td>9974.0</td>\n",
       "      <td>9973.0</td>\n",
       "      <td>9972.0</td>\n",
       "      <td>9971.0</td>\n",
       "      <td>9970.0</td>\n",
       "      <td>9969.0</td>\n",
       "      <td>9968.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>9998.0</td>\n",
       "      <td>9997.0</td>\n",
       "      <td>9996.0</td>\n",
       "      <td>9995.0</td>\n",
       "      <td>9994.0</td>\n",
       "      <td>9993.0</td>\n",
       "      <td>9992.0</td>\n",
       "      <td>9991.0</td>\n",
       "      <td>9990.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9978.0</td>\n",
       "      <td>9977.0</td>\n",
       "      <td>9976.0</td>\n",
       "      <td>9975.0</td>\n",
       "      <td>9974.0</td>\n",
       "      <td>9973.0</td>\n",
       "      <td>9972.0</td>\n",
       "      <td>9971.0</td>\n",
       "      <td>9970.0</td>\n",
       "      <td>9969.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sale   pre_1   pre_2   pre_3   pre_4   pre_5   pre_6   pre_7   pre_8  \\\n",
       "0        0     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "1        1     0.0     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "2        2     1.0     0.0     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "3        3     2.0     1.0     0.0     NaN     NaN     NaN     NaN     NaN   \n",
       "4        4     3.0     2.0     1.0     0.0     NaN     NaN     NaN     NaN   \n",
       "...    ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "9995  9995  9994.0  9993.0  9992.0  9991.0  9990.0  9989.0  9988.0  9987.0   \n",
       "9996  9996  9995.0  9994.0  9993.0  9992.0  9991.0  9990.0  9989.0  9988.0   \n",
       "9997  9997  9996.0  9995.0  9994.0  9993.0  9992.0  9991.0  9990.0  9989.0   \n",
       "9998  9998  9997.0  9996.0  9995.0  9994.0  9993.0  9992.0  9991.0  9990.0   \n",
       "9999  9999  9998.0  9997.0  9996.0  9995.0  9994.0  9993.0  9992.0  9991.0   \n",
       "\n",
       "       pre_9  ...  pre_21  pre_22  pre_23  pre_24  pre_25  pre_26  pre_27  \\\n",
       "0        NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "1        NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "2        NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "3        NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "4        NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "...      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "9995  9986.0  ...  9974.0  9973.0  9972.0  9971.0  9970.0  9969.0  9968.0   \n",
       "9996  9987.0  ...  9975.0  9974.0  9973.0  9972.0  9971.0  9970.0  9969.0   \n",
       "9997  9988.0  ...  9976.0  9975.0  9974.0  9973.0  9972.0  9971.0  9970.0   \n",
       "9998  9989.0  ...  9977.0  9976.0  9975.0  9974.0  9973.0  9972.0  9971.0   \n",
       "9999  9990.0  ...  9978.0  9977.0  9976.0  9975.0  9974.0  9973.0  9972.0   \n",
       "\n",
       "      pre_28  pre_29  pre_30  \n",
       "0        NaN     NaN     NaN  \n",
       "1        NaN     NaN     NaN  \n",
       "2        NaN     NaN     NaN  \n",
       "3        NaN     NaN     NaN  \n",
       "4        NaN     NaN     NaN  \n",
       "...      ...     ...     ...  \n",
       "9995  9967.0  9966.0  9965.0  \n",
       "9996  9968.0  9967.0  9966.0  \n",
       "9997  9969.0  9968.0  9967.0  \n",
       "9998  9970.0  9969.0  9968.0  \n",
       "9999  9971.0  9970.0  9969.0  \n",
       "\n",
       "[10000 rows x 31 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "f33d2809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# days = 365 * 5\n",
    "\n",
    "# tsdata = pd.DataFrame({'sale': np.array([1, 3, 5, 7, 9, 7, 5, 3, 1, -1] * 1000)})\n",
    "tsdata = pd.DataFrame({'sale': range(1000)})\n",
    "# for i in range(1, 9):\n",
    "#     tsdata['pre_{}'.format(i)] = tsdata['sale'].shift(i)\n",
    "# tsdata.dropna(inplace=True)\n",
    "iid = 0\n",
    "pid = 0\n",
    "\n",
    "data = tsdata.to_numpy() / 100\n",
    "# scaler = MinMaxScaler() \n",
    "# data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "d84e1c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "a93f498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 1 + 3 + 3\n",
    "num_hiddens = 32\n",
    "net = RNNModel(nn.LSTM(num_inputs, num_hiddens), vocab_size=1, num_item=2, num_place=2, item_embed_size=3, place_embed_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "ddd9775e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn.weight_ih_l0 torch.Size([128, 7])\n",
      "rnn.weight_hh_l0 torch.Size([128, 32])\n",
      "rnn.bias_ih_l0 torch.Size([128])\n",
      "rnn.bias_hh_l0 torch.Size([128])\n",
      "linear.weight torch.Size([1, 32])\n",
      "linear.bias torch.Size([1])\n",
      "item_embed.weight torch.Size([2, 3])\n",
      "place_embed.weight torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    print(name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "fbaea950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('rnn.weight_ih_l0',\n",
       "              tensor([[ 1.3279e-01,  5.5129e-02,  1.0689e-01,  1.6370e-02,  5.7336e-02,\n",
       "                       -1.0306e-01,  1.1669e-01],\n",
       "                      [ 2.1842e-02, -1.5499e-01, -1.3783e-01, -1.5914e-01, -1.6705e-01,\n",
       "                        7.6211e-02,  1.0567e-01],\n",
       "                      [ 2.0697e-02,  8.0705e-02, -1.1997e-02,  2.8080e-02, -1.5677e-01,\n",
       "                       -1.7174e-01,  5.3371e-02],\n",
       "                      [-4.9831e-02,  1.3302e-02, -5.4015e-02, -1.1276e-01,  1.5479e-02,\n",
       "                        5.3492e-03,  3.6677e-02],\n",
       "                      [ 4.0697e-02,  2.1063e-02,  2.5974e-02,  1.0895e-01, -3.8742e-02,\n",
       "                        1.0740e-01, -1.7658e-01],\n",
       "                      [ 1.6507e-01,  1.4495e-01, -1.1953e-01, -1.6611e-01, -7.5069e-03,\n",
       "                        1.1296e-02,  1.5656e-01],\n",
       "                      [ 9.5326e-02, -7.5979e-02, -1.2545e-01, -3.8579e-03, -2.4358e-02,\n",
       "                        6.1704e-03, -7.6666e-02],\n",
       "                      [ 7.6612e-02, -8.5256e-02,  3.5542e-04, -7.0130e-02,  1.4519e-01,\n",
       "                       -2.4741e-02, -4.3137e-03],\n",
       "                      [-7.2099e-02,  3.4634e-02, -1.0735e-01, -1.0137e-01,  2.4082e-02,\n",
       "                       -8.6700e-02,  1.7330e-01],\n",
       "                      [-1.2266e-01,  2.4112e-04, -3.0179e-02,  5.9370e-02, -4.8565e-02,\n",
       "                       -1.0195e-01, -7.1846e-02],\n",
       "                      [ 1.1950e-02, -1.1239e-02, -9.4730e-02,  1.4741e-01,  3.3039e-02,\n",
       "                       -1.4092e-01,  1.0757e-01],\n",
       "                      [-6.1347e-02, -7.5187e-02,  1.2334e-01,  1.1243e-01,  6.8713e-02,\n",
       "                        1.3352e-01, -1.7499e-01],\n",
       "                      [ 1.3206e-01,  8.3956e-02,  3.0576e-02, -1.6680e-01,  1.2592e-01,\n",
       "                       -1.3479e-01, -6.8483e-02],\n",
       "                      [ 1.0140e-01, -1.6533e-01, -1.6579e-01, -1.1364e-02,  1.4465e-01,\n",
       "                        7.8419e-02, -3.9357e-02],\n",
       "                      [ 9.7528e-02, -5.7940e-02,  5.5147e-02,  9.4181e-03, -1.7304e-01,\n",
       "                       -1.4703e-01,  5.4704e-03],\n",
       "                      [-1.1211e-01,  7.6566e-02,  6.6780e-02,  1.2486e-04,  1.5042e-01,\n",
       "                        1.7530e-02,  1.7846e-03],\n",
       "                      [ 1.2880e-01, -5.6561e-02,  2.7558e-03, -3.9617e-02,  1.1564e-01,\n",
       "                        8.3445e-02, -9.2176e-02],\n",
       "                      [ 9.4364e-02, -7.8855e-02, -6.8603e-02,  1.1457e-01, -7.0870e-03,\n",
       "                        1.5366e-01,  1.1959e-01],\n",
       "                      [-4.1303e-02,  1.4106e-01,  9.6386e-02,  1.3585e-01,  9.9251e-02,\n",
       "                        1.6934e-01, -2.0007e-02],\n",
       "                      [ 5.2695e-02, -9.8894e-02, -9.1356e-02, -2.8512e-03,  1.7468e-01,\n",
       "                       -7.9173e-02, -1.4692e-01],\n",
       "                      [-6.7836e-03, -1.4877e-01,  9.3088e-02, -9.8288e-02,  2.1415e-03,\n",
       "                       -1.4256e-01, -2.1482e-02],\n",
       "                      [-7.8418e-02,  1.5572e-01, -8.1094e-02, -4.6315e-02,  5.4429e-02,\n",
       "                       -1.4123e-01, -1.6002e-01],\n",
       "                      [-1.2423e-01,  1.0786e-01, -1.3091e-01,  4.7109e-03, -4.0181e-02,\n",
       "                        9.1103e-02,  6.2054e-02],\n",
       "                      [ 1.3062e-01,  5.7040e-03, -1.6827e-01,  5.1219e-02,  1.0392e-01,\n",
       "                        1.6577e-01,  1.3419e-01],\n",
       "                      [ 8.1265e-02, -9.3182e-02, -2.4345e-02,  1.0641e-01,  1.5250e-01,\n",
       "                       -9.9619e-02,  2.6520e-02],\n",
       "                      [-2.6841e-02, -1.7116e-01, -1.7088e-01,  3.8769e-02,  3.3931e-02,\n",
       "                       -6.0408e-02,  1.4041e-02],\n",
       "                      [-1.2622e-01, -9.0318e-02, -1.6141e-01,  7.4084e-02, -1.0727e-01,\n",
       "                        1.6043e-01,  6.0047e-02],\n",
       "                      [ 1.3663e-02, -1.0998e-01,  1.6637e-01,  1.4592e-01, -1.3366e-01,\n",
       "                       -1.5772e-01,  1.2896e-01],\n",
       "                      [-1.1669e-01,  1.2834e-01,  8.7038e-02, -1.9872e-02, -2.5982e-02,\n",
       "                        1.4466e-01, -5.2517e-02],\n",
       "                      [-9.2131e-02,  3.2908e-02,  1.1854e-01,  2.7984e-02, -3.6164e-03,\n",
       "                       -5.0086e-02, -9.2014e-02],\n",
       "                      [-1.2322e-01, -1.5784e-01,  1.0465e-01,  5.2495e-02, -1.2103e-01,\n",
       "                       -1.6788e-01,  4.5689e-02],\n",
       "                      [ 1.1559e-01, -1.2722e-01,  1.0441e-01, -1.3702e-01,  1.4393e-01,\n",
       "                       -1.5894e-01,  1.7087e-01],\n",
       "                      [ 7.5545e-02,  1.1932e-01, -1.1394e-01, -4.8866e-02,  9.2178e-02,\n",
       "                        1.0013e-01,  1.5611e-01],\n",
       "                      [ 1.0673e-01, -1.5120e-01, -5.2092e-02, -7.5900e-03, -1.6823e-01,\n",
       "                        2.8085e-02, -2.6671e-02],\n",
       "                      [-1.0743e-01,  7.9384e-02, -1.1593e-02,  5.2138e-02,  3.9792e-02,\n",
       "                       -9.6692e-02, -1.1352e-01],\n",
       "                      [ 8.5923e-02, -3.4077e-02,  7.8845e-02,  6.1259e-02,  3.5800e-02,\n",
       "                        1.1096e-01,  1.3609e-02],\n",
       "                      [ 1.5783e-01,  3.1056e-02, -6.2186e-02, -9.9902e-02, -1.6830e-01,\n",
       "                       -7.0653e-02,  8.6909e-02],\n",
       "                      [-1.8011e-02, -1.4289e-01, -8.9362e-03,  8.9427e-02,  1.2771e-01,\n",
       "                       -1.5675e-01, -8.4182e-02],\n",
       "                      [-7.8919e-02,  6.2074e-03,  2.4790e-02,  4.9768e-02, -1.9391e-02,\n",
       "                        3.8986e-02, -1.2574e-01],\n",
       "                      [-7.0481e-02, -1.2312e-01, -1.4831e-01,  1.3790e-01,  1.0792e-01,\n",
       "                       -1.5624e-01, -2.2041e-02],\n",
       "                      [-8.5566e-02,  3.4350e-02,  5.6191e-02, -1.0404e-01,  1.6656e-02,\n",
       "                        2.2472e-02,  2.7615e-02],\n",
       "                      [-5.7382e-02, -1.4130e-01,  8.9149e-02,  1.3337e-01,  2.1878e-02,\n",
       "                        1.6745e-01,  1.1715e-01],\n",
       "                      [ 8.3832e-03, -1.1457e-01, -2.5781e-02, -1.5175e-01, -3.6413e-02,\n",
       "                        1.0637e-01, -1.3387e-01],\n",
       "                      [-3.4433e-02,  8.9269e-02,  9.1870e-02,  1.6633e-01, -1.3924e-01,\n",
       "                        9.6969e-02, -1.7063e-01],\n",
       "                      [ 1.6704e-01,  6.5012e-02, -9.7843e-02,  1.4850e-01, -8.9755e-02,\n",
       "                       -6.9012e-04,  2.6149e-02],\n",
       "                      [ 1.6944e-02,  5.9771e-02,  6.5450e-02,  7.8646e-02,  3.2336e-02,\n",
       "                       -8.2256e-02, -9.7169e-02],\n",
       "                      [-1.3331e-01,  1.6920e-01, -1.2559e-01, -3.7209e-02, -1.0439e-01,\n",
       "                       -1.6991e-01,  1.3125e-01],\n",
       "                      [ 1.7151e-02, -1.6455e-01,  9.6170e-02,  7.2908e-03, -9.2700e-02,\n",
       "                        6.9399e-02,  9.4368e-02],\n",
       "                      [ 1.6645e-01, -1.1971e-02,  1.1250e-01,  1.7115e-01, -2.7119e-02,\n",
       "                        1.0833e-01,  1.1032e-01],\n",
       "                      [ 8.6888e-02, -1.3000e-01,  2.3815e-02, -7.6115e-02,  1.7374e-01,\n",
       "                       -1.6661e-02, -2.3080e-02],\n",
       "                      [ 3.8971e-02,  2.8299e-02, -1.3499e-01,  1.0868e-01,  1.7567e-01,\n",
       "                        1.6895e-01, -1.3710e-01],\n",
       "                      [-1.3392e-03,  5.1784e-02,  1.0336e-01, -7.7945e-02, -1.1889e-01,\n",
       "                       -1.7483e-01, -1.1721e-02],\n",
       "                      [ 8.1594e-02,  1.7217e-01,  1.4054e-01,  1.3074e-01, -3.1843e-02,\n",
       "                        1.5534e-01, -8.1126e-02],\n",
       "                      [-7.3699e-02, -1.1048e-01,  1.7331e-01,  6.7824e-02,  1.0017e-01,\n",
       "                       -1.1798e-01,  2.7789e-02],\n",
       "                      [ 1.6099e-01,  7.6704e-02,  1.6654e-01,  9.0317e-02, -1.4845e-01,\n",
       "                       -3.6307e-02,  1.7606e-01],\n",
       "                      [ 8.1004e-02, -7.0420e-02, -1.1395e-01, -2.5894e-02,  3.8124e-02,\n",
       "                       -1.7245e-01,  4.8155e-02],\n",
       "                      [ 1.4612e-01, -2.0659e-02,  1.5046e-01,  1.4498e-01, -8.3276e-02,\n",
       "                       -4.3989e-02,  1.7363e-01],\n",
       "                      [-4.6683e-02,  9.3542e-02,  3.0731e-02,  1.2368e-01, -7.6438e-02,\n",
       "                        1.6408e-01,  1.0298e-01],\n",
       "                      [ 2.4076e-02,  9.7322e-03,  5.5289e-02, -8.0322e-03,  3.0343e-02,\n",
       "                       -9.6583e-02,  1.3690e-02],\n",
       "                      [-1.3573e-01, -7.7940e-02,  1.4888e-01, -1.1813e-01, -2.3290e-02,\n",
       "                       -1.7272e-01, -1.1934e-02],\n",
       "                      [-1.0249e-01, -2.6658e-03, -2.6594e-02, -1.4944e-02, -3.4809e-04,\n",
       "                       -1.0385e-02,  1.5971e-01],\n",
       "                      [ 9.4120e-02,  7.7637e-02,  8.2499e-02, -8.9690e-02, -1.1761e-01,\n",
       "                       -2.2399e-02, -4.9700e-02],\n",
       "                      [-1.8162e-02, -9.3714e-02,  1.4470e-01,  1.0260e-01, -1.1507e-01,\n",
       "                        8.8928e-02, -6.5586e-02],\n",
       "                      [ 4.4221e-02,  1.6342e-01, -2.5346e-02, -9.5604e-02, -1.7457e-01,\n",
       "                        8.3040e-02,  1.1180e-01],\n",
       "                      [ 4.7304e-02, -4.7083e-02, -7.4396e-02,  1.3513e-01,  1.7322e-02,\n",
       "                       -1.0227e-01,  1.1988e-01],\n",
       "                      [ 1.1672e-01, -3.6836e-02, -3.7787e-02, -1.3454e-01,  1.2105e-01,\n",
       "                        1.1627e-01, -1.0744e-01],\n",
       "                      [ 7.2050e-02,  9.2343e-02,  2.2616e-02, -1.3494e-01, -1.2348e-01,\n",
       "                        1.5959e-01,  7.7523e-02],\n",
       "                      [-6.4451e-02, -9.0533e-02,  1.8333e-02,  5.8091e-02,  5.1651e-02,\n",
       "                        1.4064e-01,  1.0336e-01],\n",
       "                      [-8.6407e-02,  1.1114e-02,  1.5516e-01, -1.4352e-01, -3.7330e-02,\n",
       "                       -1.0710e-01, -4.0225e-02],\n",
       "                      [ 2.5168e-02, -6.7292e-03,  1.5613e-01,  3.0004e-02,  9.9436e-02,\n",
       "                        3.8610e-02,  2.9438e-02],\n",
       "                      [-1.7434e-01, -5.5482e-02, -6.0766e-02,  9.9354e-02,  1.4573e-01,\n",
       "                       -6.4539e-02,  1.3901e-01],\n",
       "                      [ 1.5501e-02, -1.4244e-01, -4.3786e-02,  9.2980e-02,  3.2365e-02,\n",
       "                        6.1436e-02,  1.4896e-02],\n",
       "                      [-1.0759e-01, -1.4710e-01,  8.8493e-02,  1.4551e-01, -1.0497e-02,\n",
       "                        1.6525e-01, -1.1196e-01],\n",
       "                      [ 1.1409e-01,  9.6491e-02,  1.0951e-01,  5.2539e-02, -1.3354e-01,\n",
       "                       -1.5890e-01,  1.7058e-01],\n",
       "                      [-1.7169e-01,  1.5676e-01,  1.5984e-01,  1.1993e-01, -6.2186e-02,\n",
       "                       -8.1227e-02,  2.0015e-02],\n",
       "                      [-3.2881e-02, -6.2179e-03, -7.1271e-02, -5.6529e-02,  2.5681e-02,\n",
       "                        1.7325e-01,  1.2321e-01],\n",
       "                      [-1.1280e-01,  3.8372e-02,  2.9958e-02,  1.5102e-01,  1.1250e-01,\n",
       "                        1.4395e-01,  7.8712e-02],\n",
       "                      [-1.7219e-01, -9.0991e-02,  1.4578e-01,  1.3543e-01,  1.7369e-01,\n",
       "                        1.3806e-01,  8.6134e-02],\n",
       "                      [-1.3492e-01,  1.1330e-02,  1.6103e-01,  4.6409e-02,  7.0858e-02,\n",
       "                       -2.4584e-03, -5.8972e-02],\n",
       "                      [-1.4830e-01, -1.1060e-01,  8.0557e-02,  7.2002e-02, -8.1735e-02,\n",
       "                        1.5953e-01,  1.5716e-01],\n",
       "                      [ 1.1659e-01,  1.7175e-01,  1.2910e-01,  8.6930e-03, -1.7641e-01,\n",
       "                        8.0448e-02, -2.4744e-03],\n",
       "                      [ 7.2205e-02, -1.6379e-01, -5.3776e-02,  6.8642e-02, -1.5047e-01,\n",
       "                        1.0313e-02, -3.3824e-02],\n",
       "                      [-1.0890e-01,  1.3886e-01, -1.6026e-01, -1.6190e-01,  2.4109e-02,\n",
       "                        1.4864e-01,  1.6893e-01],\n",
       "                      [ 1.4194e-01, -1.7234e-01, -3.7595e-02,  1.6617e-02, -1.6949e-01,\n",
       "                        8.1913e-02, -1.6268e-02],\n",
       "                      [ 1.1458e-02,  1.3206e-01, -1.7027e-01, -4.1081e-02, -3.4804e-02,\n",
       "                        1.3796e-01,  4.2159e-02],\n",
       "                      [-5.7898e-02, -9.2353e-02, -1.6020e-01, -1.5588e-01,  5.4598e-05,\n",
       "                       -9.8781e-02,  1.6513e-01],\n",
       "                      [ 4.5996e-02,  1.6997e-01, -5.6117e-02, -4.1682e-02,  1.6356e-01,\n",
       "                       -4.7557e-02, -8.2508e-02],\n",
       "                      [-9.8312e-03, -1.2652e-02,  1.0167e-01,  4.7550e-02,  7.7744e-02,\n",
       "                        1.4345e-01, -4.9060e-02],\n",
       "                      [-1.4468e-01, -8.1306e-02,  1.7640e-01,  1.2125e-01,  1.2887e-01,\n",
       "                        1.5336e-01, -6.3712e-02],\n",
       "                      [ 1.7337e-01, -7.8019e-02, -3.0055e-03, -9.7021e-03,  1.6957e-02,\n",
       "                       -1.3097e-01, -2.6767e-02],\n",
       "                      [-9.1148e-02,  2.1926e-02,  1.2550e-01, -1.2986e-01, -2.5025e-02,\n",
       "                        1.4639e-01,  4.9221e-02],\n",
       "                      [-6.2308e-03,  5.9216e-02,  7.9708e-02, -1.6043e-01,  8.4956e-02,\n",
       "                        1.1100e-01, -1.0085e-01],\n",
       "                      [ 6.0796e-02,  1.4457e-01,  6.0933e-02,  8.0809e-02, -1.3983e-01,\n",
       "                        1.9539e-02, -1.3610e-01],\n",
       "                      [-9.7246e-03,  1.4305e-01,  4.4658e-02, -1.6684e-01, -1.3671e-01,\n",
       "                        1.3936e-01,  1.2831e-01],\n",
       "                      [-1.7617e-01, -4.3091e-02, -4.6586e-02,  6.4964e-03,  1.0590e-01,\n",
       "                        1.7632e-01, -1.2271e-01],\n",
       "                      [-9.4809e-02, -8.2793e-02,  1.4249e-01, -4.0172e-02, -1.3570e-01,\n",
       "                        1.3592e-01,  1.0367e-01],\n",
       "                      [-1.6687e-01, -1.2609e-01, -7.6031e-02,  6.6145e-02,  1.0051e-01,\n",
       "                        1.6661e-01,  2.7174e-02],\n",
       "                      [-1.7280e-01,  1.5664e-01,  5.9942e-02, -1.5992e-01, -7.1766e-02,\n",
       "                       -1.4213e-01,  1.3809e-01],\n",
       "                      [-5.7697e-02, -6.6106e-02, -1.2092e-02,  1.6065e-01, -1.4377e-01,\n",
       "                        1.1086e-01, -4.1134e-02],\n",
       "                      [-1.4828e-01,  1.6709e-01, -9.6457e-02,  9.1377e-02, -1.2811e-01,\n",
       "                       -1.4433e-01,  7.6851e-02],\n",
       "                      [-1.4092e-02, -8.1982e-02, -9.9234e-02, -1.6917e-01, -9.4022e-02,\n",
       "                       -1.4333e-01, -1.1089e-02],\n",
       "                      [ 1.5593e-01,  3.9245e-02, -1.3150e-01,  7.5114e-02,  5.8786e-02,\n",
       "                        5.2414e-02,  6.5495e-02],\n",
       "                      [ 6.8065e-02, -1.4138e-01,  8.0025e-02, -4.3971e-02,  9.6440e-02,\n",
       "                        9.4846e-02, -9.4331e-02],\n",
       "                      [ 2.1177e-03, -4.4794e-02, -1.2074e-01,  1.5035e-01, -1.7650e-02,\n",
       "                        2.5291e-02,  1.4483e-01],\n",
       "                      [-1.1384e-01,  1.0481e-04, -2.7156e-02, -6.1728e-02, -1.6230e-01,\n",
       "                        4.8494e-02,  1.4863e-02],\n",
       "                      [ 8.4664e-02,  3.4292e-02, -6.1783e-02,  5.7416e-02, -1.4899e-01,\n",
       "                       -7.7250e-02, -7.4337e-02],\n",
       "                      [-7.4916e-02,  1.2777e-01,  5.7297e-02, -7.5380e-02,  1.3200e-01,\n",
       "                        1.6613e-02,  1.1422e-01],\n",
       "                      [-1.6675e-01,  8.9251e-02,  7.0021e-02, -6.8702e-02,  2.0544e-02,\n",
       "                        1.3423e-01,  1.4142e-01],\n",
       "                      [ 1.6601e-01, -1.5403e-01, -4.9948e-02, -9.8584e-02,  1.0922e-01,\n",
       "                        1.3145e-01, -1.2525e-01],\n",
       "                      [ 9.9635e-02, -1.0962e-01, -1.6340e-01, -1.0095e-01, -1.3812e-01,\n",
       "                       -1.0975e-01,  1.2972e-01],\n",
       "                      [ 5.7517e-02, -1.5456e-01,  4.6214e-02,  1.7625e-01, -7.1317e-02,\n",
       "                        8.4919e-02,  1.6579e-02],\n",
       "                      [ 1.5579e-01, -6.3666e-02, -1.6851e-01, -1.2336e-01, -1.1868e-01,\n",
       "                       -1.3641e-01, -4.3741e-02],\n",
       "                      [-1.0001e-01,  1.3167e-01,  2.2743e-02,  5.0004e-02, -3.9380e-02,\n",
       "                        1.6527e-01,  3.7887e-02],\n",
       "                      [ 1.3812e-01, -1.1229e-01, -3.3107e-02, -1.5188e-01, -1.9678e-02,\n",
       "                       -5.1175e-02,  7.8904e-02],\n",
       "                      [ 8.1363e-02,  2.2917e-02, -2.7477e-02, -9.1219e-02, -5.1568e-02,\n",
       "                       -6.0248e-02, -1.2869e-01],\n",
       "                      [-1.0510e-01,  1.7542e-01,  1.2139e-01, -1.0100e-01,  1.5142e-01,\n",
       "                       -6.7951e-02, -4.3418e-02],\n",
       "                      [-1.7283e-01,  2.4450e-02, -1.2332e-01, -2.6372e-02,  6.1773e-02,\n",
       "                        1.0868e-01,  3.1247e-02],\n",
       "                      [-1.2221e-01,  3.6823e-02, -1.2110e-01,  1.1651e-01, -1.1166e-01,\n",
       "                        8.5741e-02, -1.3066e-01],\n",
       "                      [ 1.2453e-01, -1.5339e-01,  1.2201e-01,  1.7225e-01, -9.5544e-02,\n",
       "                       -1.5232e-01, -4.4879e-02],\n",
       "                      [ 1.3066e-01, -1.4113e-01,  1.4626e-01, -7.7968e-02, -1.0659e-02,\n",
       "                        7.1714e-02,  9.6415e-02],\n",
       "                      [-9.5904e-02, -9.7749e-02,  9.6172e-04, -2.8207e-02, -8.5769e-03,\n",
       "                        1.0946e-01,  6.7025e-02],\n",
       "                      [ 9.0758e-02, -1.0240e-01,  1.1538e-01, -1.0235e-01, -1.7460e-01,\n",
       "                       -3.6504e-02, -1.1352e-02],\n",
       "                      [-6.8300e-03, -6.3393e-02,  1.7089e-01, -1.3936e-01,  9.6864e-02,\n",
       "                       -3.5975e-02, -6.3479e-02],\n",
       "                      [-8.1094e-02, -1.5482e-01, -3.6945e-02,  7.4774e-02,  1.3852e-01,\n",
       "                        1.7318e-02,  1.6987e-01],\n",
       "                      [-1.1071e-01, -1.1204e-01, -8.8669e-02,  4.3956e-02, -3.9630e-02,\n",
       "                        1.0498e-01,  2.6951e-02],\n",
       "                      [-1.2081e-02, -1.7401e-01, -1.7958e-02, -5.1317e-02, -1.6428e-02,\n",
       "                        9.0602e-02, -4.0103e-02],\n",
       "                      [-1.0204e-01, -5.8102e-03, -3.0685e-02, -1.5472e-01,  5.5140e-02,\n",
       "                       -4.5125e-02, -3.6760e-03],\n",
       "                      [-9.6555e-02,  1.2221e-01, -2.8929e-02, -1.2332e-01,  1.2967e-01,\n",
       "                       -1.6724e-01,  1.2714e-01]])),\n",
       "             ('rnn.weight_hh_l0',\n",
       "              tensor([[-0.1245, -0.1109,  0.1735,  ...,  0.0524, -0.0033,  0.0529],\n",
       "                      [ 0.0093, -0.1455,  0.1161,  ...,  0.0797, -0.1208,  0.0152],\n",
       "                      [-0.1447,  0.0121,  0.1063,  ...,  0.1038,  0.0660,  0.0964],\n",
       "                      ...,\n",
       "                      [-0.1759, -0.0278,  0.1398,  ...,  0.1670,  0.1513,  0.0215],\n",
       "                      [-0.1396, -0.0578,  0.0711,  ..., -0.1634,  0.1067, -0.1235],\n",
       "                      [ 0.1433,  0.1142, -0.0315,  ...,  0.0442,  0.1727,  0.1250]])),\n",
       "             ('rnn.bias_ih_l0',\n",
       "              tensor([ 0.1500, -0.0791, -0.1129, -0.0525,  0.0537,  0.1110, -0.1420, -0.1233,\n",
       "                      -0.1009,  0.0995, -0.1509,  0.0073,  0.0725,  0.1563,  0.0053, -0.0293,\n",
       "                      -0.1536,  0.1350, -0.0994,  0.0967,  0.1502, -0.0560,  0.1364, -0.1438,\n",
       "                      -0.0208, -0.0029,  0.0422, -0.0565, -0.0769,  0.1717, -0.0921,  0.1026,\n",
       "                      -0.1173,  0.0870,  0.0628,  0.0132,  0.1011, -0.1056, -0.0228,  0.0552,\n",
       "                       0.1360, -0.1651,  0.0900,  0.1398, -0.0637,  0.1586, -0.0282,  0.1482,\n",
       "                       0.0587, -0.0686, -0.0312,  0.0421, -0.0890,  0.0145,  0.1514,  0.0184,\n",
       "                      -0.0861, -0.0887, -0.1610, -0.0168,  0.0940, -0.0162, -0.0589,  0.0652,\n",
       "                      -0.1333, -0.1407,  0.0459,  0.0715,  0.1614, -0.0192, -0.1752, -0.1372,\n",
       "                       0.0937,  0.0234, -0.0709,  0.0892,  0.0701,  0.1668,  0.0345, -0.0702,\n",
       "                       0.0851,  0.1115, -0.0333, -0.1741, -0.0685, -0.0882, -0.0634, -0.1359,\n",
       "                       0.1136,  0.1415,  0.1290,  0.1093, -0.1398,  0.1255, -0.1721,  0.0831,\n",
       "                       0.1139, -0.0702,  0.0516,  0.0629, -0.0754, -0.1282,  0.0975, -0.1225,\n",
       "                      -0.0223, -0.1487,  0.1457,  0.1349,  0.0003, -0.1725, -0.0007,  0.0527,\n",
       "                      -0.0231, -0.0307,  0.0091, -0.0223, -0.0974, -0.0042,  0.0506,  0.1508,\n",
       "                       0.1643,  0.1273, -0.0713,  0.0852, -0.1700, -0.0208, -0.0767, -0.1607])),\n",
       "             ('rnn.bias_hh_l0',\n",
       "              tensor([ 0.1153,  0.0933,  0.1344, -0.0929, -0.0307,  0.0506,  0.1605,  0.1522,\n",
       "                      -0.0333, -0.0843, -0.0132, -0.0842,  0.1681, -0.1406, -0.1457,  0.1185,\n",
       "                      -0.0072,  0.1657,  0.1441, -0.1357,  0.0918, -0.0221,  0.0003,  0.0599,\n",
       "                       0.1477, -0.0092,  0.0202,  0.1612, -0.0947,  0.1611, -0.1681,  0.0268,\n",
       "                       0.0424, -0.1086, -0.0126,  0.1321,  0.0729, -0.0822,  0.1524, -0.0772,\n",
       "                       0.0989,  0.0410, -0.1726, -0.0822, -0.0116, -0.0977,  0.1615, -0.0783,\n",
       "                       0.1294, -0.1255, -0.1731, -0.1082, -0.1267,  0.1690, -0.1069,  0.1091,\n",
       "                      -0.1478,  0.1565, -0.0881,  0.1625, -0.0791,  0.0704, -0.0679, -0.0684,\n",
       "                      -0.1612, -0.1101,  0.0746, -0.1426, -0.1106,  0.1435, -0.0795, -0.0796,\n",
       "                       0.1082, -0.1123, -0.0649, -0.1078,  0.1059,  0.0007,  0.1742,  0.1560,\n",
       "                      -0.1588,  0.1169, -0.0604, -0.0739,  0.1240, -0.1547,  0.1433,  0.1170,\n",
       "                       0.0637,  0.1142,  0.0832,  0.1377,  0.0193, -0.0442,  0.0198, -0.1593,\n",
       "                      -0.1484, -0.0335,  0.0168, -0.1428, -0.0263,  0.1091,  0.0966, -0.0215,\n",
       "                      -0.0356,  0.1621,  0.0396,  0.0646,  0.0181,  0.1590, -0.0334,  0.1101,\n",
       "                      -0.1203, -0.0983,  0.1620,  0.1318, -0.0140, -0.0157,  0.1634, -0.1267,\n",
       "                      -0.0633, -0.1007, -0.0324,  0.0693, -0.0854,  0.0695, -0.0784, -0.1524])),\n",
       "             ('linear.weight',\n",
       "              tensor([[ 0.0027,  0.0998, -0.1056,  0.0693,  0.0438,  0.1469, -0.0350,  0.1613,\n",
       "                       -0.1745,  0.0706, -0.1659, -0.0267, -0.0921,  0.0477,  0.0949,  0.0035,\n",
       "                        0.1563,  0.0846, -0.0089, -0.0246,  0.1750, -0.1247,  0.0570,  0.1244,\n",
       "                       -0.1077, -0.1257,  0.1174, -0.0589,  0.0605, -0.1081,  0.1613,  0.1410]])),\n",
       "             ('linear.bias', tensor([-0.0818])),\n",
       "             ('item_embed.weight',\n",
       "              tensor([[ 1.3494,  0.8121, -1.1417],\n",
       "                      [-0.2358, -0.7942,  0.8918]])),\n",
       "             ('place_embed.weight',\n",
       "              tensor([[-0.3768,  0.5361, -0.2435],\n",
       "                      [-0.4221, -1.2403,  0.8495]]))])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45c7d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.state_dict() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f2685fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[-0.0586,  0.1549, -0.1508,  0.0709, -0.0343, -0.1502,  0.0314, -0.1331,\n",
       "                       -0.0015,  0.0218, -0.1280,  0.1348,  0.0657, -0.1431, -0.1048,  0.1255,\n",
       "                        0.0743,  0.0640, -0.1502, -0.0274,  0.0878,  0.0204,  0.1213,  0.0265,\n",
       "                        0.0247,  0.1549, -0.1439,  0.0366,  0.1106,  0.1307, -0.0087, -0.0008]])),\n",
       "             ('bias', tensor([0.1611]))])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.linear.state_dict() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "25976372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[-0.0930, -0.0290,  0.0931, -0.0283, -0.0540,  0.0087, -0.0248, -0.1001,\n",
       "                       -0.0540, -0.0080,  0.0374,  0.0825, -0.1465, -0.0846,  0.0706, -0.1383,\n",
       "                        0.1404, -0.0918,  0.0170,  0.0838, -0.1195, -0.0074,  0.0687,  0.1334,\n",
       "                        0.0814, -0.0113, -0.0277,  0.1489, -0.0498, -0.0689,  0.1381, -0.1109]])),\n",
       "             ('bias', tensor([-0.1733]))])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.linear.state_dict() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "df005a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = SeqDataLoader(data, batch_size=256, num_steps=1, vocab_size=1)\n",
    "num_epochs, lr = 800, 0.01\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d4c6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "398d541f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, mse: 18.315536499023438, time: 0.0156097412109375\n",
      "epoch: 51, mse: 0.024247661232948303, time: 0.01004171371459961\n",
      "epoch: 101, mse: 0.009333171881735325, time: 0.00201416015625\n",
      "epoch: 151, mse: 0.009411613456904888, time: 0.010079622268676758\n",
      "epoch: 201, mse: 0.02152615785598755, time: 0.0\n",
      "epoch: 251, mse: 0.0151206711307168, time: 0.010032415390014648\n",
      "epoch: 301, mse: 0.004858304280787706, time: 0.010030984878540039\n",
      "epoch: 351, mse: 0.020061960443854332, time: 0.0020384788513183594\n",
      "epoch: 401, mse: 0.013741184026002884, time: 0.0020263195037841797\n",
      "epoch: 451, mse: 0.002203725976869464, time: 0.002016305923461914\n",
      "epoch: 501, mse: 0.014759056270122528, time: 0.008023977279663086\n",
      "epoch: 551, mse: 0.010606653988361359, time: 0.008011341094970703\n",
      "epoch: 601, mse: 0.006655978038907051, time: 0.01009678840637207\n",
      "epoch: 651, mse: 0.015625419095158577, time: 0.010052680969238281\n",
      "epoch: 701, mse: 0.00401706388220191, time: 0.010021448135375977\n",
      "epoch: 751, mse: 0.013029289431869984, time: 0.010057449340820312\n"
     ]
    }
   ],
   "source": [
    "train(net, train_iter, iid, pid, lr, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "2301d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = torch.tensor(data[50]).reshape(1, -1, 1)\n",
    "predict = predict_rnn(inputs=prefix, iid=iid, pid=pid, num_preds=5, net=net, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "0a326df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50.        , 52.2426486 , 54.6469152 , 57.26788044, 57.42036104,\n",
       "       54.7268033 ])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(predict) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "dbaf68ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = net.begin_state(batch_size=1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c91c1066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1300, 0.1200, 0.1100, 0.1000, 0.0900, 0.0800, 0.0700, 0.0600,\n",
       "          0.0500]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "2dcc4ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000],\n",
       "         [0.0100],\n",
       "         [0.0200],\n",
       "         [0.0300],\n",
       "         [0.0400],\n",
       "         [0.0500],\n",
       "         [0.0600],\n",
       "         [0.0700],\n",
       "         [0.0800],\n",
       "         [0.0900],\n",
       "         [0.1000],\n",
       "         [0.1100],\n",
       "         [0.1200],\n",
       "         [0.1300],\n",
       "         [0.1400],\n",
       "         [0.1500],\n",
       "         [0.1600],\n",
       "         [0.1700],\n",
       "         [0.1800],\n",
       "         [0.1900]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "4043bc77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0381],\n",
       "         [2.5731],\n",
       "         [5.1342],\n",
       "         [6.6531],\n",
       "         [7.2177],\n",
       "         [7.4545],\n",
       "         [7.5659],\n",
       "         [7.6180],\n",
       "         [7.6429],\n",
       "         [7.6554],\n",
       "         [7.6622],\n",
       "         [7.6666],\n",
       "         [7.6698],\n",
       "         [7.6725],\n",
       "         [7.6750],\n",
       "         [7.6774],\n",
       "         [7.6797],\n",
       "         [7.6820],\n",
       "         [7.6843],\n",
       "         [7.6866]], grad_fn=<AddmmBackward>),\n",
       " (tensor([[[ 1.6607e-03,  9.9963e-01,  4.2697e-01,  9.9999e-01, -9.9987e-01,\n",
       "             9.5105e-01, -9.9994e-01, -5.1971e-01,  9.9961e-01,  4.2324e-01,\n",
       "            -9.9997e-01, -1.3191e-05,  1.0000e+00, -9.9994e-01,  9.9999e-01,\n",
       "             1.4608e-03,  7.2114e-01,  1.6778e-14, -1.9352e-08,  1.0000e+00,\n",
       "             5.7262e-10,  9.9462e-01,  1.0000e+00,  9.9997e-01,  4.8186e-05,\n",
       "             1.0000e+00, -9.9988e-01, -2.3140e-08, -9.9995e-01,  9.9982e-01,\n",
       "            -8.8307e-02, -9.9967e-01]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[ 2.1297e-01,  1.8905e+01,  1.5022e+01,  1.8026e+01, -1.8584e+01,\n",
       "             1.7310e+01, -1.7923e+01, -1.1365e+00,  1.8284e+01,  1.8634e+01,\n",
       "            -1.7902e+01, -6.2592e-03,  1.9443e+01, -1.8054e+01,  1.8256e+01,\n",
       "             8.2410e-02,  1.6946e+01,  1.6952e-08, -1.9170e-04,  1.9178e+01,\n",
       "             1.3569e-05,  1.6774e+01,  1.9558e+01,  1.8584e+01,  8.6884e-02,\n",
       "             1.9059e+01, -1.8661e+01, -1.0716e-04, -1.8952e+01,  1.7265e+01,\n",
       "            -1.8390e+01, -1.5910e+01]]], grad_fn=<StackBackward>)))"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = torch.tensor(data[:20]).reshape(1, -1, 1)\n",
    "\n",
    "net(prefix, iid, pid, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a030e744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "52611919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.01,\n",
       " 0.02,\n",
       " 0.03,\n",
       " 0.04,\n",
       " 0.05,\n",
       " 0.06,\n",
       " 0.07,\n",
       " 0.08,\n",
       " 0.09,\n",
       " 0.1,\n",
       " 0.11,\n",
       " 0.12,\n",
       " 0.13,\n",
       " 0.14,\n",
       " 0.15,\n",
       " 0.16,\n",
       " 0.17,\n",
       " 0.18,\n",
       " 0.19,\n",
       " 0.2,\n",
       " 0.21,\n",
       " 0.22,\n",
       " 0.23,\n",
       " 0.24,\n",
       " 0.25,\n",
       " 0.26,\n",
       " 0.27,\n",
       " 0.28,\n",
       " 0.29,\n",
       " 0.3,\n",
       " 0.31,\n",
       " 0.32,\n",
       " 0.33,\n",
       " 0.34,\n",
       " 0.35,\n",
       " 0.36,\n",
       " 0.37,\n",
       " 0.38,\n",
       " 0.39,\n",
       " 0.4,\n",
       " 0.41,\n",
       " 0.42,\n",
       " 0.43,\n",
       " 0.44,\n",
       " 0.45,\n",
       " 0.46,\n",
       " 0.47,\n",
       " 0.48,\n",
       " 0.49,\n",
       " 0.5,\n",
       " 0.51,\n",
       " 0.52,\n",
       " 0.53,\n",
       " 0.54,\n",
       " 0.55,\n",
       " 0.56,\n",
       " 0.57,\n",
       " 0.58,\n",
       " 0.59,\n",
       " 0.6,\n",
       " 0.61,\n",
       " 0.62,\n",
       " 0.63,\n",
       " 0.64,\n",
       " 0.65,\n",
       " 0.66,\n",
       " 0.67,\n",
       " 0.68,\n",
       " 0.69,\n",
       " 0.7,\n",
       " 0.71,\n",
       " 0.72,\n",
       " 0.73,\n",
       " 0.74,\n",
       " 0.75,\n",
       " 0.76,\n",
       " 0.77,\n",
       " 0.78,\n",
       " 0.79,\n",
       " 0.8,\n",
       " 0.81,\n",
       " 0.82,\n",
       " 0.83,\n",
       " 0.84,\n",
       " 0.85,\n",
       " 0.86,\n",
       " 0.87,\n",
       " 0.88,\n",
       " 0.89,\n",
       " 0.9,\n",
       " 0.91,\n",
       " 0.92,\n",
       " 0.93,\n",
       " 0.94,\n",
       " 0.95,\n",
       " 0.96,\n",
       " 0.97,\n",
       " 0.98,\n",
       " 0.99,\n",
       " 46.3619384765625,\n",
       " 46.940086364746094,\n",
       " 46.944618225097656,\n",
       " 46.94465637207031,\n",
       " 46.94465637207031,\n",
       " 46.94465637207031,\n",
       " 46.94465637207031,\n",
       " 46.94465637207031,\n",
       " 46.94465637207031,\n",
       " 46.94465637207031]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00062a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d140fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.inverse_transform(np.array(predict).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f6c966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
