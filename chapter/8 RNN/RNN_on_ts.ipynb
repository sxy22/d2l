{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03b1b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c81c7654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d4a9e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4c53c728",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataLoader:  \n",
    "    \"\"\"序列数据迭代器\"\"\"\n",
    "    def __init__(self, corpus, batch_size, num_steps, vocab_size):\n",
    "        self.corpus = corpus\n",
    "        self.batch_size, self.num_steps = batch_size, num_steps\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.seq_data_iter_sequential(self.corpus, self.batch_size, self.num_steps, self.vocab_size)\n",
    "    \n",
    "    def seq_data_iter_sequential(self, corpus, batch_size, num_steps, vocab_size):\n",
    "        \"\"\"顺序生成一个小批量子序列\"\"\"\n",
    "        # 从随机偏移量开始划分序列\n",
    "        offset = random.randint(0, num_steps)\n",
    "        num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size\n",
    "        Xs = torch.tensor(corpus[offset: offset + num_tokens], dtype=torch.float32)\n",
    "        Ys = torch.tensor(corpus[offset + 1: offset + 1 + num_tokens], dtype=torch.float32)\n",
    "        Xs, Ys = Xs.reshape(batch_size, -1, vocab_size), Ys.reshape(batch_size, -1, vocab_size)\n",
    "        num_batches = Xs.shape[1] // num_steps\n",
    "        for i in range(0, num_steps * num_batches, num_steps):\n",
    "            X = Xs[:, i: i + num_steps]\n",
    "            Y = Ys[:, i: i + num_steps][:, :, 0]\n",
    "            yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6a1d2a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    \"\"\"循环神经网络模型\"\"\"\n",
    "    def __init__(self, rnn_layer, vocab_size, num_item, num_place, item_embed_size=5, place_embed_size=5, **kwargs):\n",
    "        super(RNNModel, self).__init__(**kwargs)\n",
    "        self.rnn = rnn_layer\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_hiddens = self.rnn.hidden_size\n",
    "        if not self.rnn.bidirectional:\n",
    "            self.num_directions = 1\n",
    "            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)\n",
    "        else:\n",
    "            self.num_directions = 2\n",
    "            self.linear = nn.Linear(self.num_hiddens * 2, self.vocab_size)\n",
    "        # item 和 place的embedding\n",
    "        self.num_item = num_item\n",
    "        self.num_place = num_place\n",
    "        self.item_embed_size = item_embed_size\n",
    "        self.place_embed_size = place_embed_size\n",
    "        self.item_embed = nn.Embedding(num_embeddings=num_item, embedding_dim=item_embed_size)\n",
    "        self.place_embed = nn.Embedding(num_embeddings=num_place, embedding_dim=place_embed_size)\n",
    "        \n",
    "\n",
    "    def forward(self, inputs, iid, pid, state):\n",
    "        iid_tensor = torch.full((inputs.shape[0], inputs.shape[1], 1), iid)\n",
    "        pid_tensor = torch.full((inputs.shape[0], inputs.shape[1], 1), pid)\n",
    "        iid_embed = self.item_embed(iid_tensor).view(inputs.shape[0], inputs.shape[1], self.item_embed_size)\n",
    "        pid_embed = self.place_embed(pid_tensor).view(inputs.shape[0], inputs.shape[1], self.place_embed_size)\n",
    "        X = torch.cat((inputs, iid_embed, pid_embed), dim=-1)\n",
    "        # 时间步数*批量大小,隐藏单元数\n",
    "        X.transpose_(0, 1)\n",
    "        X = X.to(torch.float32)\n",
    "        Y, state = self.rnn(X, state)\n",
    "        # 将Y的形状改为(时间步数*批量大小,隐藏单元数)\n",
    "        # 输出(时间步数*批量大小,词表大小)。\n",
    "        output = self.linear(Y.reshape((-1, Y.shape[-1])))\n",
    "        return output, state\n",
    "\n",
    "    def begin_state(self, device, batch_size=1):\n",
    "        if not isinstance(self.rnn, nn.LSTM):\n",
    "            # nn.GRU以张量作为隐状态\n",
    "            return  torch.zeros((self.num_directions * self.rnn.num_layers,\n",
    "                                 batch_size, self.num_hiddens),\n",
    "                                device=device)\n",
    "        else:\n",
    "            # nn.LSTM以元组作为隐状态\n",
    "            return (torch.zeros((\n",
    "                self.num_directions * self.rnn.num_layers,\n",
    "                batch_size, self.num_hiddens), device=device),\n",
    "                    torch.zeros((\n",
    "                        self.num_directions * self.rnn.num_layers,\n",
    "                        batch_size, self.num_hiddens), device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6a7aa336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping(net, theta):  #@save\n",
    "    \"\"\"裁剪梯度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm\n",
    "\n",
    "def train_epoch(net, train_iter, iid, pid, loss, updater, device, use_random_iter):\n",
    "    \"\"\"训练网络一个迭代周期\"\"\"\n",
    "    state = None\n",
    "    start_time = time.time()\n",
    "    mse = 0\n",
    "    size = 0\n",
    "    for X, Y in train_iter:\n",
    "        if state is None or use_random_iter:\n",
    "            # 在第一次迭代或使用随机抽样时初始化state\n",
    "            state = net.begin_state(batch_size=X.shape[0], device=device)\n",
    "        else:\n",
    "            if isinstance(net, nn.Module) and not isinstance(state, tuple):\n",
    "                # state对于nn.GRU是个张量\n",
    "                state.detach_()\n",
    "            else:\n",
    "                for s in state:\n",
    "                    s.detach_()\n",
    "                    \n",
    "        # y = Y.reshape(-1)\n",
    "        y = Y.transpose(0, 1).reshape(-1)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat, state = net(X, iid, pid, state)\n",
    "        l = loss(y_hat.reshape(-1), y)\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            updater.zero_grad()\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            updater.step()\n",
    "        else:\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            updater(batch_size=1)\n",
    "        mse += l * y.numel()\n",
    "        size += y.numel()\n",
    "    \n",
    "    return mse / size, time.time() - start_time\n",
    "\n",
    "def train(net, train_iter, iid, pid, lr, num_epochs, device, use_random_iter=False):\n",
    "    \"\"\"训练模型\"\"\"\n",
    "    loss = nn.MSELoss()\n",
    "    # 初始化\n",
    "    updater = torch.optim.Adam(net.parameters(), lr)\n",
    "    # 训练\n",
    "    for epoch in range(num_epochs):\n",
    "        epochmse, speed = train_epoch(\n",
    "            net, train_iter, iid, pid, loss, updater, device, use_random_iter)\n",
    "        if epoch == 0:\n",
    "            print(f'epoch: {epoch + 1}, mse: {epochmse}, time: {speed}')\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f'epoch: {epoch + 1}, mse: {epochmse}, time: {speed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ff0c6e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rnn(inputs, iid, pid, num_preds, net, device):\n",
    "    \"\"\"向后预测\"\"\"\n",
    "    state = net.begin_state(batch_size=1, device=device)\n",
    "    outputs = inputs.flatten().tolist() \n",
    "    # 预热\n",
    "    Y, state = net(inputs, iid=iid, pid=pid, state=state)\n",
    "    # 向后第一步\n",
    "    outputs.append(Y.flatten()[-1].item())\n",
    "    for _ in range(num_preds - 1):  # 预测num_preds步\n",
    "        Y, state = net(torch.tensor(outputs[-1]).view(1, 1, 1), iid=iid, pid=pid, state=state)\n",
    "        outputs.append(Y.item())\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a810105b",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f33d2809",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsdata = pd.DataFrame({'sale': np.array([1,3,5,7,9,7,5,3] * 1000)})\n",
    "# for i in range(1, 9):\n",
    "#     tsdata['pre_{}'.format(i)] = tsdata['sale'].shift(i)\n",
    "# tsdata.dropna(inplace=True)\n",
    "iid = 0\n",
    "pid = 0\n",
    "data = tsdata.to_numpy()\n",
    "scaler = MinMaxScaler() \n",
    "data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d84e1c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_steps = 128, 10\n",
    "num_inputs = 1 + 3 + 3\n",
    "num_hiddens = 16\n",
    "net = RNNModel(nn.LSTM(num_inputs, num_hiddens), vocab_size=1, num_item=2, num_place=2, item_embed_size=3, place_embed_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ddd9775e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn.weight_ih_l0 torch.Size([64, 7])\n",
      "rnn.weight_hh_l0 torch.Size([64, 16])\n",
      "rnn.bias_ih_l0 torch.Size([64])\n",
      "rnn.bias_hh_l0 torch.Size([64])\n",
      "linear.weight torch.Size([1, 16])\n",
      "linear.bias torch.Size([1])\n",
      "item_embed.weight torch.Size([2, 3])\n",
      "place_embed.weight torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    print(name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "df005a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "train_iter = SeqDataLoader(data, batch_size=batch_size, num_steps=num_steps, vocab_size=1)\n",
    "num_epochs, lr = 500, 0.01\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "398d541f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, mse: 0.20028053224086761, time: 0.04900360107421875\n",
      "epoch: 100, mse: 0.0012313289334997535, time: 0.05304884910583496\n",
      "epoch: 200, mse: 0.0011149842757731676, time: 0.05504727363586426\n",
      "epoch: 300, mse: 0.0007263133302330971, time: 0.04502129554748535\n",
      "epoch: 400, mse: 0.0006801017443649471, time: 0.05305743217468262\n",
      "epoch: 500, mse: 0.0010754867689684033, time: 0.05202531814575195\n"
     ]
    }
   ],
   "source": [
    "train(net, train_iter, iid, pid, lr, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2301d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = torch.tensor(data[-15:]).reshape(1, -1, 1)\n",
    "predict = predict_rnn(inputs=prefix, iid=iid, pid=pid, num_preds=15, net=net, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d140fa19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.        ],\n",
       "       [5.        ],\n",
       "       [7.        ],\n",
       "       [9.        ],\n",
       "       [7.        ],\n",
       "       [5.        ],\n",
       "       [3.        ],\n",
       "       [1.        ],\n",
       "       [3.        ],\n",
       "       [5.        ],\n",
       "       [7.        ],\n",
       "       [9.        ],\n",
       "       [7.        ],\n",
       "       [5.        ],\n",
       "       [3.        ],\n",
       "       [1.02027948],\n",
       "       [3.03399801],\n",
       "       [5.04173279],\n",
       "       [7.09666777],\n",
       "       [9.10932255],\n",
       "       [7.01463938],\n",
       "       [5.01331282],\n",
       "       [3.04564166],\n",
       "       [1.04226877],\n",
       "       [3.02850676],\n",
       "       [5.03665257],\n",
       "       [7.08926201],\n",
       "       [9.10710621],\n",
       "       [7.01918173],\n",
       "       [5.01760435]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.inverse_transform(np.array(predict).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511a99b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e791f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4284e549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e479c7c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>goodsqty</th>\n",
       "      <th>goodsid</th>\n",
       "      <th>placepointid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-14</td>\n",
       "      <td>-2.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-15</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-12-16</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2018-09-05</td>\n",
       "      <td>19.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2018-09-06</td>\n",
       "      <td>19.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>2018-09-07</td>\n",
       "      <td>18.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>2018-09-08</td>\n",
       "      <td>20.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>2018-09-09</td>\n",
       "      <td>22.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1003 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  goodsqty  goodsid  placepointid\n",
       "0    2015-12-12      0.00        1             0\n",
       "1    2015-12-13     -0.98        1             0\n",
       "2    2015-12-14     -2.96        1             0\n",
       "3    2015-12-15     -0.94        1             0\n",
       "4    2015-12-16      2.08        1             0\n",
       "...         ...       ...      ...           ...\n",
       "998  2018-09-05     19.96        1             0\n",
       "999  2018-09-06     19.98        1             0\n",
       "1000 2018-09-07     18.00        1             0\n",
       "1001 2018-09-08     20.02        1             0\n",
       "1002 2018-09-09     22.04        1             0\n",
       "\n",
       "[1003 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "def gene(start_date, end_date, gid, pid):\n",
    "    dr = pd.date_range(start_date, end_date)\n",
    "    n = len(dr)\n",
    "    qty = np.arange(n) / 50 + np.random.randint(-3, 3, n)\n",
    "    df = pd.DataFrame({'date': dr, \n",
    "                      'goodsqty': qty,\n",
    "                      'goodsid': gid,\n",
    "                      'placepointid': pid})\n",
    "    return df\n",
    "\n",
    "# 根据goodsid， placepointid 获取对应的时间序列数据\n",
    "def get_subdata(data, gid, pid):\n",
    "    return data[(data['goodsid'] == gid) & (data['placepointid'] == pid)]\n",
    "    \n",
    "# 生成虚拟数据, 四个组合 (0, 0),(0, 1),(1, 0),(1, 1)\n",
    "data = pd.concat((gene('1997-1-1', '1999-4-5', 0, 0), \n",
    "           gene('2020-1-1', '2022-3-3', 0, 1),\n",
    "           gene('2015-12-12', '2018-9-9', 1, 0),\n",
    "           gene('2025-6-9', '2027-9-9', 1, 1)), axis=0)\n",
    "\n",
    "# 选出 goodsid = 0, placepointid = 0 的数据\n",
    "subdata = get_subdata(data, 1, 0)\n",
    "\n",
    "# 对日期排序\n",
    "subdata = subdata.sort_values(by=['date'])\n",
    "\n",
    "# 对subdata fit 一个ts模型 ......\n",
    "subdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fbb220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
